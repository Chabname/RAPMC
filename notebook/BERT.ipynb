{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Using cached huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from transformers) (4.62.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\radja\\miniconda3\\envs\\deep\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Installing collected packages: pyparsing, pyyaml, packaging, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.3.1 huggingface-hub-0.0.19 packaging-21.0 pyparsing-2.4.7 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.DistilBertModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/3761948243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDistilBertModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.DistilBertModel'"
     ]
    }
   ],
   "source": [
    "import transformers.DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization # tokenization.py\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import transformers\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ragou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords: the,a,an etc.\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def pre_processing(data):\n",
    "    # lowercase text\n",
    "    data = data.apply(lambda x: \" \".join(i.lower() for i in  str(x).split()))\n",
    "#     # remove numeric values\n",
    "#     data = data.str.replace(\"\\d\",\"\")\n",
    "#     # remove punctuations\n",
    "#     data = data.str.replace(\"[^\\w\\s]\",\"\")\n",
    "    # remove stopwords: the,a,an etc.\n",
    "    data = data.apply(lambda x: \" \".join(i for i in x.split() if i not in sw))\n",
    "    data = data.apply(lambda x: re.sub(\"⇓\",\"\",x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datas/all_data_clean.txt\"\n",
    "dtf = pd.read_csv(data_file, sep = \"\\|\\|\", engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>truncating mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>here, we deorphanize cdk10 by identifying cyc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>w802*</td>\n",
       "      <td>2</td>\n",
       "      <td>the c-cbl loh also positively correlated wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>q249e</td>\n",
       "      <td>2</td>\n",
       "      <td>the c-cbl loh also positively correlated wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>n454d</td>\n",
       "      <td>3</td>\n",
       "      <td>most of the changes were novel, although 4 c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>l399v</td>\n",
       "      <td>4</td>\n",
       "      <td>all mutations from the second group were pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3316</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>d171n</td>\n",
       "      <td>4</td>\n",
       "      <td>21–29 the vast majority of aml1 mutations wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3317</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>a122*</td>\n",
       "      <td>1</td>\n",
       "      <td>(a) spleen from morbid mice/d171n (left) and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3318</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>fusions</td>\n",
       "      <td>1</td>\n",
       "      <td>lpxn is preferentially expressed in hematopo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3319</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>r80c</td>\n",
       "      <td>4</td>\n",
       "      <td>) conversely, mutations mapping to the first ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3320</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>k83e</td>\n",
       "      <td>4</td>\n",
       "      <td>mutation analysis in fpd/aml pedigrees. elec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Gene               Variation  Class  \\\n",
       "0        0   FAM58A    truncating mutations       1   \n",
       "1        1      CBL                   w802*       2   \n",
       "2        2      CBL                   q249e       2   \n",
       "3        3      CBL                   n454d       3   \n",
       "4        4      CBL                   l399v       4   \n",
       "...    ...       ...                     ...    ...   \n",
       "3311  3316    RUNX1                   d171n       4   \n",
       "3312  3317    RUNX1                   a122*       1   \n",
       "3313  3318    RUNX1                 fusions       1   \n",
       "3314  3319    RUNX1                    r80c       4   \n",
       "3315  3320    RUNX1                    k83e       4   \n",
       "\n",
       "                                                   Text  Score  \n",
       "0      here, we deorphanize cdk10 by identifying cyc...      2  \n",
       "1       the c-cbl loh also positively correlated wit...      1  \n",
       "2       the c-cbl loh also positively correlated wit...      1  \n",
       "3       most of the changes were novel, although 4 c...      1  \n",
       "4       all mutations from the second group were pre...      1  \n",
       "...                                                 ...    ...  \n",
       "3311   21–29 the vast majority of aml1 mutations wer...      1  \n",
       "3312    (a) spleen from morbid mice/d171n (left) and...      2  \n",
       "3313    lpxn is preferentially expressed in hematopo...      1  \n",
       "3314   ) conversely, mutations mapping to the first ...      1  \n",
       "3315    mutation analysis in fpd/aml pedigrees. elec...      1  \n",
       "\n",
       "[3316 rows x 6 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        here, we deorphanize cdk10 by identifying cyc...\n",
       "1         the c-cbl loh also positively correlated wit...\n",
       "2         the c-cbl loh also positively correlated wit...\n",
       "3         most of the changes were novel, although 4 c...\n",
       "4         all mutations from the second group were pre...\n",
       "                              ...                        \n",
       "3311     21–29 the vast majority of aml1 mutations wer...\n",
       "3312      (a) spleen from morbid mice/d171n (left) and...\n",
       "3313      lpxn is preferentially expressed in hematopo...\n",
       "3314     ) conversely, mutations mapping to the first ...\n",
       "3315      mutation analysis in fpd/aml pedigrees. elec...\n",
       "Name: Text, Length: 3316, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_y = dtf[\"Text\"]\n",
    "text_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pre_processing(text_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       here, deorphanize cdk10 identifying cyclin m, ...\n",
       "1       c-cbl loh also positively correlated egfr met ...\n",
       "2       c-cbl loh also positively correlated egfr met ...\n",
       "3       changes novel, although 4 cases r420q previous...\n",
       "4       mutations second group predicted benign accord...\n",
       "                              ...                        \n",
       "3311    21–29 vast majority aml1 mutations located run...\n",
       "3312    (a) spleen morbid mice/d171n (left) normal mic...\n",
       "3313    lpxn preferentially expressed hematopoietic ce...\n",
       "3314    ) conversely, mutations mapping first dna inte...\n",
       "3315    mutation analysis fpd/aml pedigrees. electroph...\n",
       "Name: Text, Length: 3316, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dtf.drop(columns = [\"Score\"], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = [\"ID\",\"Gene\",\"Variation\",\"Class\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>truncating mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>here, we deorphanize cdk10 by identifying cyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>w802*</td>\n",
       "      <td>2</td>\n",
       "      <td>the c-cbl loh also positively correlated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>q249e</td>\n",
       "      <td>2</td>\n",
       "      <td>the c-cbl loh also positively correlated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>n454d</td>\n",
       "      <td>3</td>\n",
       "      <td>most of the changes were novel, although 4 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>l399v</td>\n",
       "      <td>4</td>\n",
       "      <td>all mutations from the second group were pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3316</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>d171n</td>\n",
       "      <td>4</td>\n",
       "      <td>21–29 the vast majority of aml1 mutations wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3317</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>a122*</td>\n",
       "      <td>1</td>\n",
       "      <td>(a) spleen from morbid mice/d171n (left) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3318</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>fusions</td>\n",
       "      <td>1</td>\n",
       "      <td>lpxn is preferentially expressed in hematopo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3319</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>r80c</td>\n",
       "      <td>4</td>\n",
       "      <td>) conversely, mutations mapping to the first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3320</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>k83e</td>\n",
       "      <td>4</td>\n",
       "      <td>mutation analysis in fpd/aml pedigrees. elec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Gene               Variation  Class  \\\n",
       "0        0   FAM58A    truncating mutations       1   \n",
       "1        1      CBL                   w802*       2   \n",
       "2        2      CBL                   q249e       2   \n",
       "3        3      CBL                   n454d       3   \n",
       "4        4      CBL                   l399v       4   \n",
       "...    ...       ...                     ...    ...   \n",
       "3311  3316    RUNX1                   d171n       4   \n",
       "3312  3317    RUNX1                   a122*       1   \n",
       "3313  3318    RUNX1                 fusions       1   \n",
       "3314  3319    RUNX1                    r80c       4   \n",
       "3315  3320    RUNX1                    k83e       4   \n",
       "\n",
       "                                                   Text  \n",
       "0      here, we deorphanize cdk10 by identifying cyc...  \n",
       "1       the c-cbl loh also positively correlated wit...  \n",
       "2       the c-cbl loh also positively correlated wit...  \n",
       "3       most of the changes were novel, although 4 c...  \n",
       "4       all mutations from the second group were pre...  \n",
       "...                                                 ...  \n",
       "3311   21–29 the vast majority of aml1 mutations wer...  \n",
       "3312    (a) spleen from morbid mice/d171n (left) and...  \n",
       "3313    lpxn is preferentially expressed in hematopo...  \n",
       "3314   ) conversely, mutations mapping to the first ...  \n",
       "3315    mutation analysis in fpd/aml pedigrees. elec...  \n",
       "\n",
       "[3316 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2652,) (2652, 9)\n",
      "(664,) (664, 9)\n"
     ]
    }
   ],
   "source": [
    "Y_D = pd.get_dummies(dataset['Class']).values\n",
    "XD_train, XD_test, YD_train, YD_test = train_test_split(X, Y_D, test_size = 0.2, random_state = 42, stratify=Y_D)\n",
    "print(XD_train.shape, YD_train.shape)\n",
    "print(XD_test.shape, YD_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893     results 80 tumors (%) pdgfra mutation: 66 exon...\n",
       "2819    addition, n319t nh2 terminus brca2 included no...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XD_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(m_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=250):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    \n",
    "    #clf_output = sequence_output[:, 0, :]\n",
    "    \n",
    "    # CNN model\n",
    "    \n",
    "    net = tf.keras.layers.Conv1D(64, (5), activation='relu')(sequence_output)\n",
    "    net = tf.keras.layers.MaxPooling1D(2)(net)\n",
    "    \n",
    "#     net = tf.keras.layers.Conv1D(64, (5), activation='relu')(net)\n",
    "#     net = tf.keras.layers.GlobalMaxPooling1D()(net)\n",
    "    \n",
    "\n",
    "    net = tf.keras.layers.Dense(20, activation=\"relu\")(net)\n",
    "    net = tf.keras.layers.Flatten()(net)    \n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    out = tf.keras.layers.Dense(9, activation=\"softmax\")(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(XD_train.head(10), tokenizer, max_len=250)\n",
    "test_input = bert_encode(XD_test, tokenizer, max_len=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        multiple             109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 246, 64)      245824      keras_layer[41][1]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 123, 64)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 123, 20)      1300        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2460)         0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2460)         0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 9)            22149       dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,751,514\n",
      "Trainable params: 109,751,513\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=250)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 52s 52s/step - loss: 2.5736 - accuracy: 0.0000e+00 - val_loss: 4.3942 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to model_bert.h5\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 39s 39s/step - loss: 2.0751 - accuracy: 0.5000 - val_loss: 2.5006 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.00000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 39s 39s/step - loss: 1.7821 - accuracy: 0.3750 - val_loss: 11.6123 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.00000 to 0.50000, saving model to model_bert.h5\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_bert.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3,verbose=1)\n",
    "\n",
    "train_sh = model.fit(\n",
    "    train_input, YD_train[:10],\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo4ElEQVR4nO3deXxU5b3H8c8ve8KiYXFjEVzqrqBIqXurtu60bixi3SpdbNW2t63W9mp77a33trdVq1bR2mrFCIK4Feu+1LIZFBUURdwIIARkJ3t+949zApMhCUnIzJnl+3695sXknDMz35wMv2fO8zxzjrk7IiKSPXKiDiAiIsmlwi8ikmVU+EVEsowKv4hIllHhFxHJMir8IiJZRoVfRCTLqPCLtMDM/mZmN7Zz24/N7KTtbHODmT3QNelEdowKv4hIllHhFxHJMir8ktbCbpafmNlbZrbJzP5iZrua2VNmtsHMnjOz0nDbs8xsgZmtNbOXzOyAmOcZamavh4+ZBBTFvc4ZZjYvfOwMMzt0B3O3leVnZrY0zPKemZ0YLh9uZuVmtt7MVpjZH3Ykg2QvFX7JBOcAJwNfAM4EngJ+DvQleI9faWZfAMqAq8Pl04EnzKzAzAqAR4G/A72Ah8PnBIJGAbgX+DbQG7gLeNzMCjsTdjtZ9gO+Dxzp7j2ArwEfhw+9BbjF3XsCewOTO/P6Iir8kgn+5O4r3H0p8C9gtru/4e7VwDRgKDAK+Ie7P+vudcDvgWLgKGAEkA/c7O517j4FeC3m+ccDd7n7bHdvcPf7gJrwcZ3RVpYGoBA40Mzy3f1jd18cPq4O2MfM+rj7Rnef1cnXlyynwi+ZYEXM/aoWfu4O7AF80rTQ3RuBJUC/cN1Sb36q2k9i7u8J/DjslllrZmuBAeHjOqPVLO7+AcGRwA3ASjN7yMyaXucygqOahWb2mpmd0cnXlyynwi/ZYhlBAQfAzIygeC8FlgP9wmVNBsbcXwL8xt13jrmVuHtZArLg7g+6+zHhNg78T7h8kbuPAXYJl00xs26dzCBZTIVfssVk4HQzO9HM8oEfE3TXzABmAvUEYwH5ZnY2MDzmsXcD3zGzL1qgm5mdbmY9ujqLme1nZl8Jxw+qCY5YGgHMbJyZ9Q2PENaGz9XYyQySxVT4JSu4+3vAOOBPwCqCQeAz3b3W3WuBs4GLgc8J+uAfiXlsOXA5cBuwBvgg3LbLsxD0798ULv+M4NP9teFDTwEWmNlGgoHe0e5e1dkckr1MV+ASEcku+sQvIpJlVPhFukj4pbGNLdx+HnU2kVgJ6+oxs3uBM4CV7n5wuOx3BP2ZtcBi4BJ3X5uQACIi0qJEFv7jgI3A/TGF/6vAC+5eb2ZNU9R+tr3n6tOnjw8aNCghOUVEMtXcuXNXuXvf+OV5iXpBd3/FzAbFLXsm5sdZwLntea5BgwZRXl7ehelERDKfmX3S0vIo+/gvJTinSovMbHx4QqryysrKJMYSEclskRR+M7uO4AszE1vbxt0nuPswdx/Wt+82RyoiItJJCevqaY2ZXUww6Hui60sEIiJJl9TCb2anAD8Fjnf3zTvyXHV1dVRUVFBdXd014VJUUVER/fv3Jz8/P+ooIpIhElb4zawMOAHoY2YVwPUEXz0vBJ4Nz4c1y92/05nnr6iooEePHgwaNIjm59bKHO7O6tWrqaioYPDgwVHHEZEMkchZPWNaWPyXrnr+6urqjC76AGZG79690eC2iHSltP7mbiYX/SbZ8DuKSHKldeEXEclYtZth+k9h8+dd/tQq/J20du1a7rjjjg4/7rTTTmPt2rVdH0hEMoc7PHYFzJkAS1/v8qdX4e+k1gp/fX19m4+bPn06O++8c4JSiUhGePl/YcEjcNL1sO9JXf70SZ/HnymuueYaFi9ezJAhQ8jPz6eoqIjS0lIWLlzI+++/z9e//nWWLFlCdXU1V111FePHjwe2nn5i48aNnHrqqRxzzDHMmDGDfv368dhjj1FcXBzxbyYikVrwKLz033DYGDj66oS8REYU/l89sYB3lq3v0uc8cI+eXH/mQa2uv+mmm5g/fz7z5s3jpZde4vTTT2f+/Plbpl3ee++99OrVi6qqKo488kjOOeccevfu3ew5Fi1aRFlZGXfffTfnn38+U6dOZdy4cV36e4hIGlk2D6Z9B/oPhzNuhgRN7siIwp8Khg8f3myu/a233sq0adMAWLJkCYsWLdqm8A8ePJghQ4YAcMQRR/Dxxx8nK66IpJoNn8FDY6GkN4yeCPlFCXupjCj8bX0yT5Zu3bptuf/SSy/x3HPPMXPmTEpKSjjhhBNa/IZxYWHhlvu5ublUVenyqSJZqa4aHroAqtbApU9D910S+nIZUfij0KNHDzZs2NDiunXr1lFaWkpJSQkLFy5k1qxZSU4nImnDHR7/Piwth1EPwO6HJvwlVfg7qXfv3hx99NEcfPDBFBcXs+uuu25Zd8opp3DnnXdywAEHsN9++zFixIgIk4pISnv1D/D2w/CVX8ABZyblJRN2Ba6uNGzYMI+/EMu7777LAQccEFGi5Mqm31Ukq7z7JEy6AA4+F865p8sHc81srrsPi1+uefwiIlH47G14ZDzscTiMvC1hM3haosIvIpJsG1fCg6OhaCcYUwb5yf3+jvr4RUSSqb4GJo2Dzavh0qegx25Jj6DCLyKSLO7wxFWwZDac9zfYY2gkMdTVIyKSLDNuhTfL4IRr4aBvRBZDhV9EJBneewqevT4o+Mf/LNIoKvxJ0r1796gjiEhUVrwDU78Fux8GI+9I6gyelqjwi4gk0qZVUDYKCroHM3gKSqJOpMHdzrrmmmsYMGAAV1xxBQA33HADeXl5vPjii6xZs4a6ujpuvPFGRo4cGXFSEYlMfS1MujCYvnnxdOi5R9SJgEwp/E9dE3wZoivtdgicelOrq0eNGsXVV1+9pfBPnjyZp59+miuvvJKePXuyatUqRowYwVlnnaXr5opkI3f4xw/h0xlwzl+g/xFRJ9oiMwp/BIYOHcrKlStZtmwZlZWVlJaWsttuu/HDH/6QV155hZycHJYuXcqKFSvYbbfkz9MVkYjNugPeeACO+wkccm7UaZrJjMLfxifzRDrvvPOYMmUKn332GaNGjWLixIlUVlYyd+5c8vPzGTRoUIunYxaRDLfoWXjmF7D/GXDCz6NOs43MKPwRGTVqFJdffjmrVq3i5ZdfZvLkyeyyyy7k5+fz4osv8sknn0QdUUSSrfI9mHIp7HoQnD0BclJvDo0K/w446KCD2LBhA/369WP33Xfnggsu4Mwzz+SQQw5h2LBh7L///lFHFJFk2vw5PDgK8opgdBkUdNv+YyKgwr+D3n5766Bynz59mDlzZovbbdy4MVmRRCQKDXUw+Zuwfilc/A/YeUDUiVqlwi8isqPcYfpP4ON/wTfuggHDo07UptTrfBIRSTdzJsDcv8LRV8Nho6NOs11pXfjT4ephOyobfkeRtPbB8/DPa2C/0+DE66NO0y5pW/iLiopYvXp1RhdGd2f16tUUFRVFHUVEWrJqETx8CfQ9IGVn8LQkbfv4+/fvT0VFBZWVlVFHSaiioiL69+8fdQwRiVe1JpjBk5sfnIOnsEfUidotbQt/fn4+gwcPjjqGiGSjhjp4+GJY+ylc9ASU7hl1og5J2HGJmd1rZivNbH7Msl5m9qyZLQr/LU3U64uIJMw/r4UPX4Izb4E9vxR1mg5LZIfU34BT4pZdAzzv7vsCz4c/i4ikj9fugdfuhi99H4ZeEHWaTklY4Xf3V4DP4xaPBO4L798HfD1Rry8i0uU+fBmm/xT2/Sqc/Ouo03Rasoegd3X35eH9z4BdW9vQzMabWbmZlWf6AK6IpIHVi4Nv5vbZNzjNck5u1Ik6LbK5Rx7Mw2x1Lqa7T3D3Ye4+rG/fvklMJiISp2ptMIPHcmDMQ1DUM+pEOyTZhX+Fme0OEP67MsmvLyLSMQ31wdk213wEo/4OvdJ/NmGyC//jwEXh/YuAx5L8+iIiHfPML2Dx83D6/8GgY6JO0yUSOZ2zDJgJ7GdmFWZ2GXATcLKZLQJOCn8WEUlNc/8Gs/8MX/wuHHFx1Gm6TMK+wOXuY1pZdWKiXlNEpMt8/Cr848ew94nw1RujTtOl0uPEEiIiyfT5RzDpQigdDOfeC7lpe5KDFqnwi4jEql4PZaPBG2HsJCjeOepEXS6zmjERkR3R2ABTLwvOunnhNOi9d9SJEkKFX0SkyXPXw6Jnghk8ex0fdZqEUVePiAjAGxNhxp/gyMvhyG9FnSahVPhFRD6ZCU9cBYOPh1N+G3WahFPhF5HstuYTmDQOdh4I598XXFglw6nwi0j2qtkAZWOCC6uMnQTF2XGJEA3uikh2amyER8ZD5UK44OHgrJtZQoVfRLLTC7+G96bDqf8L+2TXCQXU1SMi2efNh+DVP8IRl8Dw8VGnSToVfhHJLkteg8d/AIOOhdN+B2ZRJ0o6FX4RyR5rl8BDY6HnHnD+/Vkxg6cl6uMXkexQuwkeGgP11XDRE1DSK+pEkVHhF5HM19gI074NKxbA2Mmwy/5RJ4qUCr+IZL6X/hvefQK+9t+w78lRp4mc+vhFJLO9PQVe+R0MHQcjvhd1mpSgwi8imatiLjx2BQw8Ck7/Y1bO4GmJCr+IZKb1y4IZPN13gVF/h7yCqBOlDPXxi0jmqd0cnIOndiNc+Cx06xN1opSiwi8imcUdHvseLH8TxpTBrgdGnSjlqPCLSGZ5+X9gwTQ46Vew36lRp0lJ6uMXkcyxYBq89Fs4bAwcfVXUaVKWCr+IZIZlb8C070L/4XDmLZrB0wYVfhFJfxs+g7KxwSDu6ImQVxh1opSmPn4RSW91VcG0zep1cNnTwfRNaZMKv4ikL3d47PuwdC6Mmgi7HRJ1orSgrh4RSV//+j+YPwW+8ks44Iyo06QNFX4RSU/vPgEv/Bccch4c++Oo06QVFX4RST/L3woulN7vCDjrT5rB00Eq/CKSXjauDE7HUFwKox+E/OKoE6WdSAq/mf3QzBaY2XwzKzOzoihyiEiaqauGhy6AzauDot9jt6gTpaWkF34z6wdcCQxz94OBXGB0snOISJpxhyevhoo58I07YY8hUSdKW1F19eQBxWaWB5QAyyLKISLp4t+3wJtlcMLP4aCvR50mrSW98Lv7UuD3wKfAcmCduz8Tv52ZjTezcjMrr6ysTHZMEUklC6fDczfAQWfD8T+NOk3ai6KrpxQYCQwG9gC6mdm4+O3cfYK7D3P3YX379k12TBFJFSsWwCOXB107I2/XDJ4uEEVXz0nAR+5e6e51wCPAURHkEJFUt2kVlI2Ggu7BYG5BSdSJMkIUhf9TYISZlZiZAScC70aQQ0RSWX0NTBoXTN8c8yD03CPqRBkjij7+2cAU4HXg7TDDhGTnEJEU5g5P/gg+nRl07/Q7IupEGSWSk7S5+/XA9VG8toikgZm3w7wH4LifwiHnRp0m4+ibuyKSWt5/Bp79JRxwFpxwbdRpMpIKv4ikjpULYcqlsOvBwZe0clSiEkF7VURSw6bVUDYqOPfOmDIo6BZ1ooylC7GISPTqa2HyN2H9crj4H7BT/6gTZTQVfhGJljs89RP45FU4+24YcGTUiTKeunpEJFqz74K5f4NjfgSHnh91mqygwi8i0fngeXj6Wtjv9ODyiZIUKvwiEo3K9+HhS2CXA+HsCZrBk0Ta0yKSfJs/D2bw5OYHM3gKu0edKKtocFdEkquhDh6+GNZVwEVPwM4Do06UdVT4RSS5/nkNfPQyjLwDBo6IOk1WUlePiCTPnLvhtXvgqB/A0AuiTpO1VPhFJDk+fAme+hl84RQ46VdRp8lqKvwiknirF8Pki6DPF4IvaeXkRp0oq7Wr8JvZVWbW0wJ/MbPXzeyriQ4nIhmgai08OAosJ5jBU9Qz6kRZr72f+C919/XAV4FS4ELgpoSlEpHM0FAPUy6BNR/BqAeg1+CoEwntL/xNVzc+Dfi7uy+IWSYi0rJnroPFL8Dpf4BBR0edRkLtLfxzzewZgsL/tJn1ABoTF0tE0l75X2H2nTDie3DERVGnkRjtncd/GTAE+NDdN5tZL+CShKUSkfT20b9g+n/APifByf8VdRqJ095P/F8C3nP3tWY2DvgFsC5xsUQkbX3+EUy+EHrtBefeC7n6nmiqaW/h/zOw2cwOA34MLAbuT1gqEUlP1euhbHRwf8xDULRTtHmkRe0t/PXu7sBI4DZ3vx3okbhYIpJ2Ghtg6mWw+gM4/37ovXfUiaQV7T0G22Bm1xJM4zzWzHKA/MTFEpG08+x/wqJnghk8g4+LOo20ob2f+EcBNQTz+T8D+gO/S1gqEUkvbzwAM2+D4ePhyMuiTiPb0a7CHxb7icBOZnYGUO3u6uMXEfhkBjxxNex1Anztt1GnkXZo7ykbzgfmAOcB5wOzzezcRAYTkTSw5hOYNA5K94Tz/qYZPGmivX+l64Aj3X0lgJn1BZ4DpiQqmIikuJoNwQyexnoYMwmKS6NOJO3U3sKf01T0Q6vRmT1FsldjA0y9HCrfg3FToM8+USeSDmhv4f+nmT0NlIU/jwKmJyaSiKS8538N7z8Fp/4O9v5K1Gmkg9pV+N39J2Z2DtB0lqUJ7j4tcbFEJGXNK4N/3wzDLoXhl0edRjqh3SMx7j4VmJrALCKS6pbMgSeuhEHHwqn/C6aT9KajNgu/mW0AvKVVgLt7p66oYGY7A/cAB4fPf6m7z+zMc4lIkqxdAg+NhZ79gm/m5uo7nOmqzcLv7ok6LcMtwD/d/VwzKwBKEvQ6ItIVajZC2Rior4GL/wElvaJOJDsg6ZNuzWwn4DjgYgB3rwVqk51DRNqpsRGmfRtWLoCxD0Pf/aJOJDsoiimZg4FK4K9m9oaZ3WNm3eI3MrPxZlZuZuWVlZXJTykigRd/AwufhK/+BvY9Keo00gWiKPx5wOHAn919KLAJuCZ+I3ef4O7D3H1Y3759k51RRADeehj+9XsYeiGM+G7UaaSLRFH4K4AKd58d/jyFoCEQkVRSMRceuwL2PDo446Zm8GSMpBf+8IRvS8ysqaPwROCdZOcQkTasWwoPjYEeu8L5f4e8gqgTSReK6oxKPwAmhjN6PkTX7xVJHbWbg6JfuwkufBS69Y46kXSxSAq/u88DhkXx2iLShsZGePS7sPyt4NKJux4YdSJJAJ1DVUS2evl/4J1H4eRfw36nRJ1GEkRn2BSRwPxH4OWb4LCxcNSVUaeRBFLhFxFY9gY8+j0Y8EU482bN4MlwKvwi2W798uB0DN36wKiJkFcYdSJJMPXxi2SzuqrgxGvV6+GyZ6C7viyZDVT4RbKVe/AFrWVvwOiJsNvBUSeSJFFXj0i2+tfvYf5UOPGXsP/pUaeRJFLhF8lG7zwOL9wIh46CY34UdRpJMhV+kWyz/M3gNMv9hsGZt2oGTxZS4RfJJhtWQNlYKC6F0Q9CflHUiSQCGtwVyRZ11TDpAqj6HC79Z3ACNslKKvwi2cA9uEh6xWvB9XJ3PyzqRBIhdfWIZIN/3wxvTYIvXwcHjow6jURMhV8k0y2cDs/9Cg4+B477SdRpJAWo8Itkss/mw9RvwR5DYOTtmsEjgAq/SObaWBmcg6eoJ4wug/ziqBNJitDgrkgmqq+BSeNg00q45CnouXvUiSSFqPCLZBp3ePJHsGQWnHsv9Ds86kSSYtTVI5JpZt4G8x6A438WDOiKxFHhF8kk7z8Nz/wSDjgLjr8m6jSSolT4RTLFyndhymWw2yHwjTshR/+9pWV6Z4hkgk2r4cFRUFACYx6Cgm5RJ5IUpsFdkXRXXwuTvwkbPoNLpsNO/aJOJClOhV8knbnD9P+AT16Fs++B/sOiTiRpQF09Iuls9p3w+n1w7I/h0POiTiNpIrMLf0U5vPcUVK2NOolI1/vgOXj657D/GfDlX0SdRtJIZnf1vHYPvFkGGOx+KAw6FgYdAwO/BMU7R51OpPMq34eHL4VdDoRv3KUZPNIh5u5RZ9iuYcOGeXl5eccfWFcNS8vh41eD25I50FCDGgJJa5s/h3tOhJoNcPkLsPPAqBNJijKzue6+zcBPZn/izy8KCvugY4Kf4xuCOXcH33K0HNjt0HDbY2HgCDUEkpoa6uDhi2BdBVz0pIq+dEpmF/54LTUEFa/FNAQT1BBIanvqZ/DRK/D1P8PAL0adRtJUdhX+ePlFMPjY4AZQVxUMCG+vIdjzS1C0U7TZJfvMuRvK/wJHXQlDxkadRtJYZH38ZpYLlANL3f2MtrbtdB//jopvCCrmQEOtGgJJvsUvwgPnwL4nw+gHISc36kSSBlKxj/8q4F2gZ4QZ2pZfrCMCid6qD4J+/b77wTn3qOjLDouk8JtZf+B04DfAj6LI0CkdaQh2P6z5GIEaAumMqjVQNgpy8mBMGRT2iDqRZICoPvHfDPwUaPVdbGbjgfEAAwem6MyFFhuCmMHi2XfBjD+pIZDOaaiHKZfCmk/gm49B6aCoE0mGSHrhN7MzgJXuPtfMTmhtO3efAEyAoI8/Oel2UH4xDD4uuIEaAtkxT/8cFr8AZ/0JBh0ddRrJIFF84j8aOMvMTgOKgJ5m9oC7j4sgS2KpIZDOKr8X5twFI66Aw78ZdRrJMJF+czf8xP8fKTurJ9HiG4KK17bOGlJDkL0+egX+/g3Y6wQYO1mDudJpqTirRzp0RDAkriFI3clQsgNWLw7Ord9r7+BC6Sr6kgCZfa6edFe7edsjgsY6NQSZqnod3HMybFoZnIOn115RJ5I0p0/86aigBPY6PrjBtg3BrD/DjFvVEGSCxobgermfL4YLp6noS0Kp8KcTNQSZ69n/hA+ehTP+uLXrTyRBVPjTmRqCzPD6/cEX/4Z/G4ZdGnUayQLq489ktZuD8wttGSMoD8cIcmGPIVsbggFfVEMQlY//DfePDP4WF0yBXH0Wk67TWh+/Cn82aW9DMHCETg2QDGs+hru/AsWl8K3ngn9FupAGdyXsGjohuMG2DcHMO+Dft6ghSIaaDVA2BhrrYcwkFX1JKhX+bKaGIBqNDTD1W1D5HoybCn32iTqRZBkVftmqQw3B0JiG4ItqCDri+V/B+/+E034Pe3856jSShVT4pXXbNASbggvWb2kIbod/36yGoCPmPRg0nsMug+GXR51GspQGd6Xz4huCpXNjBovVEGzj09lw3xlBV9m4RyA3P+pEkuE0q0cSTw1B69Z+GszgKewB33oeSnpFnUiygAq/JN82DUF5MIsl2xqCmo1w79dg7ZJg2mbfL0SdSLKEpnNK8hV0CwYvmwYwtxkjuG3rGEG/w8OG4BgYMAIKu0cavcs0NsK0b8PKd2Dswyr6khJU+CV5WmwIZm9tCGb8CV79Y2Y1BC/eCAufhFNugn1PijqNCKCuHkkl8Q3B0rlbu4bSsSF4azI8cnlwBa0zbwWzqBNJllEfv6SfdG4IKsrhr6dB/yOD0yznFUSdSLKQCr+kv9Yagpy8mMHiFGgI1lUEM3jyiuDyF6Fb7+iySFbT4K6kv4JusPdXghu0PkaQkwd7xB4RfDF5DUHtpuAcPLWb4ZuPqehLSlLhl/QV3xDUbIxrCG6FV/+QvIagsREe/S589jaMnQS7HND1ryHSBVT4JXMUdod9TgxukPyG4OWb4J3H4Ks3whe+tuPPJ5Ig6uOX7BHfECx7PWaMYAcbgvlTYcqlMGQcjLxNM3gkJWhwVyReexuCgSOCbqXWLH0d/npqcHnLix6HvMKk/QoibcnKwv+XVz/ihYUr2Kk4n52K8+kZ/ht761mU32x9bo4+qWWtthqCfkc0PyJoagjWLwtm8OTkw+UvQPe+0f4OIjGydlZPVW0Dn62rZl1VPeur6qhtaGxz+x6FeVsaiJ7Feds0FLENSHxDkp+bk6TfShKixTGCWVsbgldvhn/9X/OG4IPnoXo9XPaMir6kjYz+xB/P3ampb2RdVd3W2+a6Zj+vrw7/rWq+fF1VHdV1bTcaJQW5zY4ktj3CyGOnkuZHGU0NSFF+7g7/fpJg8Q3B0tfBG2H0RNj/9KjTiWwjaz/xxzIzivJzKcrPZdeeRR1+fE19A+ur6rc2ErENRgsNRcWazbyzrI711fVsrKlv87kL83Ja7ZKK/blnUXgUUrJ1WXF+LqbBxMQr7A77nBTcIGgINlVCr8HR5hLpoKwq/DuqMC+Xvj1y6duj44N39Q2NrK+u36ZxaGo04huOFeureX/FBtZX1bGhpp62Dszyc21LAxF/NNG8AcnbplHpXpinRqOzCrun3qkiRNpBhT9J8nJz6NWtgF7dOn7OloZGZ2MLjUZTt1R8I7Jmcy0fr960pTFpbKPRyM0xehY1bxC2NwjedOtRlEeOBsNF0o4KfxrIzbGga6ek45fqc3c21tS3cITR8tHHuqo6lq6t2tJo1DW03mqYNR8Mb+8geFOXVZ4Gw0UiocKf4cyMHkX59CjKp39pxx7r7lTVNTQbCI/vrorvovpg5cYt92vq2x4M716Yt83RRqtjG3HrCvLUaIh0lgq/tMrMKCnIo6Qgj913Ku7w46vrGpoPgFdvbUDWxR1xrK+u49PPN2/5eXNtQ5vPXZyfu8102+aD4DENRUnzRkMzqCTbJb3wm9kA4H5gV8CBCe5+S7JzSOI1zaDapRMzqGrrG1ucWtvS7Kn1VfUsW1vNu8u3Doa3pSAvJ2wYWv+eRmtHISUFmkEl6S+KT/z1wI/d/XUz6wHMNbNn3f2dCLJIiirIy6FP90L6dO/cDKoNYZdUSwPg8eMcqzbWsrhy05bt25pBlZdjzcYuehblUZyfS3FBLsVhQ9d0vzg/l6KY+8UFORTlxS8LH5OfS36uqVGRpEh64Xf35cDy8P4GM3sX6Aeo8EuXyMvNobRbAaWdmEHV2OhsqKnfcmTR0hFG0EDUb1lfuaGG6roGquoaqKptoLqucbvfEG9Jbo7FNB5BIxHbMMQ3FMUFOVu2L4pZ33IDtHVbfcNcIu3jN7NBwFBgdpQ5RJrk5NiWbp0BO/A89Q2NVNc3hg1B0ChUhw3Dlvt1DVTVNm6zrunn2GVrq+r4bF311vW1DWyua6Chrbm6rchramC2OTLJada4tKfBiV8X2+DovFepK7LCb2bdganA1e6+voX144HxAAMHDkxyOpEdk5ebQ/fcHLoXJva/WF3D1oajOmxEth55bL0f27hU17fe4KzeVEvVmtjGp5HNtfVtfhekNQW5ORTl5zQ7Cmn5yCSnxa6xovxtj1yKC3KaNzh5ufouSSdEcq4eM8sHngSedvc/bG97nZZZJDruTl2Dt3xkEnM/aFQat13WUgMUNirN1tc1tDm+0prCvJwWjj6aNzixjU3hliOZnLgjmW2PWprWFeblpGUDkzLn6rFg9OovwLvtKfoiEi0zoyDPKAjPJ5UoTSdRbPlIpbFZA9F6AxQ0JjX1wfq1m+u2aaC2d7LF1hTlt3xkUlyQS2FeU2OR0+L62G6zohaOXJqWF+blJGWAP4qunqOBC4G3zWxeuOzn7j49giwikiJiT6K4cwJfp7ExaGDij0pa6xqrqmveLdZszKaugU019azaWLtNY1S7nS8wtsSMuK6uHH579qEMH9yrS/dBFLN6XgXS75hJRDJCTo4Fn7ILEvtFvoZGb9agNB25tNUNVhNzVNN0lJOIcSJ9c1dEJAFyc4xuhXl0S/AAf2doQq+ISJZR4RcRyTIq/CIiWUaFX0Qky6jwi4hkGRV+EZEso8IvIpJlVPhFRLJMJCdp6ygzqwQ+6eTD+wCrujBOV1GujlGujlGujknVXLBj2fZ0977xC9Oi8O8IMytv6ex0UVOujlGujlGujknVXJCYbOrqERHJMir8IiJZJhsK/4SoA7RCuTpGuTpGuTomVXNBArJlfB+/iIg0lw2f+EVEJIYKv4hIlknrwm9mp5jZe2b2gZld08L6QjObFK6fbWaDYtZdGy5/z8y+luRcPzKzd8zsLTN73sz2jFnXYGbzwtvjSc51sZlVxrz+t2LWXWRmi8LbRUnO9ceYTO+b2dqYdQnZX2Z2r5mtNLP5raw3M7s1zPyWmR0esy6R+2p7uS4I87xtZjPM7LCYdR+Hy+eZWXmSc51gZuti/lb/GbOuzb9/gnP9JCbT/PD91Ctcl8j9NcDMXgzrwAIzu6qFbRL3HnP3tLwBucBiYC+gAHgTODBum+8Bd4b3RwOTwvsHhtsXAoPD58lNYq4vAyXh/e825Qp/3hjh/roYuK2Fx/YCPgz/LQ3vlyYrV9z2PwDuTcL+Og44HJjfyvrTgKcILiM6Apid6H3VzlxHNb0ecGpTrvDnj4E+Ee2vE4And/Tv39W54rY9E3ghSftrd+Dw8H4P4P0W/j8m7D2Wzp/4hwMfuPuH7l4LPASMjNtmJHBfeH8KcKKZWbj8IXevcfePgA/C50tKLnd/0d03hz/OAvp30WvvUK42fA141t0/d/c1wLPAKRHlGgOUddFrt8rdXwE+b2OTkcD9HpgF7Gxmu5PYfbXdXO4+I3xdSN57qz37qzU78r7s6lxJeW8BuPtyd389vL8BeBfoF7dZwt5j6Vz4+wFLYn6uYNsdt2Ubd68H1gG92/nYROaKdRlBq96kyMzKzWyWmX29izJ1JNc54WHlFDMb0MHHJjIXYZfYYOCFmMWJ2l/b01ruRO6rjop/bznwjJnNNbPxEeT5kpm9aWZPmdlB4bKU2F9mVkJQPKfGLE7K/rKgC3ooMDtuVcLeY6l3FeAsYmbjgGHA8TGL93T3pWa2F/CCmb3t7ouTFOkJoMzda8zs2wRHS19J0mu3x2hgirs3xCyLcn+lLDP7MkHhPyZm8THhvtoFeNbMFoafiJPhdYK/1UYzOw14FNg3Sa/dHmcC/3b32KODhO8vM+tO0Nhc7e7ru/K525LOn/iXAgNifu4fLmtxGzPLA3YCVrfzsYnMhZmdBFwHnOXuNU3L3X1p+O+HwEsEnwSSksvdV8dkuQc4or2PTWSuGKOJOxRP4P7antZyJ3JftYuZHUrw9xvp7qublsfsq5XANLque3O73H29u28M708H8s2sDymwv0JtvbcSsr/MLJ+g6E9090da2CRx77FEDFwk40ZwtPIhwaF/06DQQXHbXEHzwd3J4f2DaD64+yFdN7jbnlxDCQa09o1bXgoUhvf7AIvoooGudubaPeb+N4BZvnUw6aMwX2l4v1eycoXb7U8w2GbJ2F/hcw6i9cHK02k+8DYn0fuqnbkGEoxZHRW3vBvQI+b+DOCUJObarelvR1BAPw33Xbv+/onKFa7fiWAcoFuy9lf4u98P3NzGNgl7j3XZzo3iRjDq/T5BEb0uXPZrgk/RAEXAw+F/hDnAXjGPvS583HvAqUnO9RywApgX3h4Plx8FvB2++d8GLktyrt8CC8LXfxHYP+axl4b78QPgkmTmCn++Abgp7nEJ218En/6WA3UEfaiXAd8BvhOuN+D2MPPbwLAk7avt5boHWBPz3ioPl+8V7qc3w7/xdUnO9f2Y99YsYhqmlv7+ycoVbnMxwWSP2Mclen8dQzCG8FbM3+q0ZL3HdMoGEZEsk859/CIi0gkq/CIiWUaFX0Qky6jwi4hkGRV+EZEso8IvkmDhmSmfjDqHSBMVfhGRLKPCLxIys3FmNic8//pdZpZrZhstuB7AAguundA33HZIeGK4t8xsmpmVhsv3MbPnwpORvW5me4dP3z088d1CM5sYniVWJBIq/CKAmR0AjAKOdvchQANwAcHX9cvd/SDgZeD68CH3Az9z90MJvlXZtHwicLu7H0bwzeLl4fKhwNUE14LYCzg6wb+SSKt0dk6RwIkEJ6V7LfwwXgysBBqBSeE2DwCPmNlOwM7u/nK4/D7gYTPrAfRz92kA7l4NED7fHHevCH+eR3D+mFcT/luJtECFXyRgwH3ufm2zhWa/jNuus+c4qYm534D+70mE1NUjEngeODc89zpm1iu88EsOcG64zVjgVXdfB6wxs2PD5RcCL3twJaWKpgvCWHDN55Jk/hIi7aFPHSKAu79jZr8guOJSDsHZHK8ANgHDw3UrCcYBAC4C7gwL+4fAJeHyC4G7zOzX4XOcl8RfQ6RddHZOkTaY2UZ37x51DpGupK4eEZEso0/8IiJZRp/4RUSyjAq/iEiWUeEXEckyKvwiIllGhV9EJMv8P6Q49o5f7RqXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sh.history['loss'])\n",
    "plt.plot(train_sh.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()\n",
    "plt.savefig(\"loss_plot.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ragou/repo/github/RAPMC/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sh.history['accuracy'])\n",
    "plt.plot(train_sh.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"acc_plot.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pretrained BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\Radja\\miniconda3\\envs\\tf_gpu_env:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_tflow_select             2.3.0                       mkl  \n",
      "abseil-cpp                20210324.2           hd77b12b_0  \n",
      "absl-py                   0.14.1                   pypi_0    pypi\n",
      "aiohttp                   3.7.4.post0      py39h2bbff1b_2  \n",
      "astor                     0.8.1            py39haa95532_0  \n",
      "astunparse                1.6.3                      py_0  \n",
      "async-timeout             3.0.1            py39haa95532_0  \n",
      "attrs                     21.2.0             pyhd3eb1b0_0  \n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "blas                      1.0                         mkl  \n",
      "blinker                   1.4              py39haa95532_0  \n",
      "boto3                     1.18.21            pyhd3eb1b0_0  \n",
      "botocore                  1.21.41            pyhd3eb1b0_1  \n",
      "bottleneck                1.3.2            py39h7cc1a96_1  \n",
      "brotlipy                  0.7.0           py39h2bbff1b_1003  \n",
      "ca-certificates           2021.9.30            haa95532_1  \n",
      "cached-property           1.5.2                      py_0  \n",
      "cachetools                4.2.4                    pypi_0    pypi\n",
      "certifi                   2021.10.8        py39haa95532_0  \n",
      "cffi                      1.14.6           py39h2bbff1b_0  \n",
      "chardet                   4.0.0           py39haa95532_1003  \n",
      "charset-normalizer        2.0.7                    pypi_0    pypi\n",
      "clang                     5.0                      pypi_0    pypi\n",
      "click                     8.0.1              pyhd3eb1b0_0  \n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \n",
      "coverage                  5.5              py39h2bbff1b_2  \n",
      "cryptography              3.4.8            py39h71e12ea_0  \n",
      "cudatoolkit               11.3.1               h59b6b97_2  \n",
      "cudnn                     8.2.1.32             h754d62a_0    conda-forge\n",
      "cycler                    0.10.0                   pypi_0    pypi\n",
      "cython                    0.29.24          py39hd77b12b_0  \n",
      "dataclasses               0.8                pyh6d0b6a4_7  \n",
      "debugpy                   1.4.1            py39hd77b12b_0  \n",
      "decorator                 5.1.0              pyhd3eb1b0_0  \n",
      "entrypoints               0.3              py39haa95532_0  \n",
      "filelock                  3.3.1                    pypi_0    pypi\n",
      "flatbuffers               1.12                     pypi_0    pypi\n",
      "gast                      0.4.0              pyhd3eb1b0_0  \n",
      "giflib                    5.2.1                h62dcd97_0  \n",
      "google-auth               2.3.0                    pypi_0    pypi\n",
      "google-auth-oauthlib      0.4.6                    pypi_0    pypi\n",
      "google-pasta              0.2.0              pyhd3eb1b0_0  \n",
      "grpcio                    1.41.0                   pypi_0    pypi\n",
      "h5py                      3.1.0                    pypi_0    pypi\n",
      "hdf5                      1.10.6               h7ebc959_0  \n",
      "huggingface-hub           0.0.19                   pypi_0    pypi\n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       68.1                 h6c2663c_0  \n",
      "idna                      3.3                      pypi_0    pypi\n",
      "importlib-metadata        4.8.1            py39haa95532_0  \n",
      "intel-openmp              2021.3.0          haa95532_3372  \n",
      "ipykernel                 6.4.1            py39haa95532_1  \n",
      "ipython                   7.27.0           py39hd4e2768_0  \n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
      "jedi                      0.18.0           py39haa95532_1  \n",
      "jmespath                  0.10.0             pyhd3eb1b0_0  \n",
      "joblib                    1.1.0                    pypi_0    pypi\n",
      "jpeg                      9d                   h2bbff1b_0  \n",
      "jupyter_client            7.0.1              pyhd3eb1b0_0  \n",
      "jupyter_core              4.8.1            py39haa95532_0  \n",
      "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \n",
      "kiwisolver                1.3.2                    pypi_0    pypi\n",
      "libcurl                   7.78.0               h86230a5_0  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libprotobuf               3.14.0               h23ce68f_0  \n",
      "libssh2                   1.9.0                h7a1dbc1_1  \n",
      "markdown                  3.3.4            py39haa95532_0  \n",
      "matplotlib                3.4.3                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \n",
      "mkl                       2021.3.0           haa95532_524  \n",
      "mkl-service               2.4.0            py39h2bbff1b_0  \n",
      "mkl_fft                   1.3.0            py39h277e83a_2  \n",
      "mkl_random                1.2.2            py39hf11a4ad_0  \n",
      "multidict                 5.1.0            py39h2bbff1b_2  \n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0  \n",
      "nltk                      3.6.5                    pypi_0    pypi\n",
      "numexpr                   2.7.3            py39hb80d3ca_1  \n",
      "numpy                     1.19.5                   pypi_0    pypi\n",
      "numpy-base                1.21.2           py39h0829f74_0  \n",
      "oauthlib                  3.1.1              pyhd3eb1b0_0  \n",
      "openssl                   1.1.1l               h2bbff1b_0  \n",
      "opt_einsum                3.3.0              pyhd3eb1b0_1  \n",
      "packaging                 21.0                     pypi_0    pypi\n",
      "pandas                    1.3.3            py39h6214cd6_0  \n",
      "parso                     0.8.2              pyhd3eb1b0_0  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.4.0                    pypi_0    pypi\n",
      "pip                       21.2.4           py39haa95532_0  \n",
      "prompt-toolkit            3.0.20             pyhd3eb1b0_0  \n",
      "protobuf                  3.18.1                   pypi_0    pypi\n",
      "pyasn1                    0.4.8              pyhd3eb1b0_0  \n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\n",
      "pycparser                 2.20                       py_2  \n",
      "pygments                  2.10.0             pyhd3eb1b0_0  \n",
      "pyjwt                     2.1.0            py39haa95532_0  \n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
      "pyparsing                 2.4.7                    pypi_0    pypi\n",
      "pyreadline                2.1              py39haa95532_1  \n",
      "pysocks                   1.7.1            py39haa95532_0  \n",
      "python                    3.9.7                h6244533_1  \n",
      "python-dateutil           2.8.2              pyhd3eb1b0_0  \n",
      "python-flatbuffers        1.12               pyhd3eb1b0_0  \n",
      "pytz                      2021.3             pyhd3eb1b0_0  \n",
      "pywin32                   228              py39hbaba5e8_1  \n",
      "pyyaml                    6.0                      pypi_0    pypi\n",
      "pyzmq                     22.2.1           py39hd77b12b_1  \n",
      "regex                     2021.10.8                pypi_0    pypi\n",
      "requests                  2.26.0             pyhd3eb1b0_0  \n",
      "requests-oauthlib         1.3.0                      py_0  \n",
      "rsa                       4.7.2              pyhd3eb1b0_1  \n",
      "s3transfer                0.5.0              pyhd3eb1b0_0  \n",
      "sacremoses                0.0.46                   pypi_0    pypi\n",
      "scikit-learn              1.0                      pypi_0    pypi\n",
      "scipy                     1.7.1            py39hbe87c03_2  \n",
      "sentencepiece             0.1.96                   pypi_0    pypi\n",
      "setuptools                58.0.4           py39haa95532_0  \n",
      "six                       1.15.0                   pypi_0    pypi\n",
      "sklearn                   0.0                      pypi_0    pypi\n",
      "snappy                    1.1.8                h33f27b4_0  \n",
      "sqlite                    3.36.0               h2bbff1b_0  \n",
      "tensorboard               2.7.0                    pypi_0    pypi\n",
      "tensorboard-data-server   0.6.1                    pypi_0    pypi\n",
      "tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\n",
      "tensorflow                2.6.0           mkl_py39h31650da_0  \n",
      "tensorflow-base           2.6.0           mkl_py39h9201259_0  \n",
      "tensorflow-estimator      2.6.0              pyh7b7c402_0  \n",
      "tensorflow-hub            0.12.0                   pypi_0    pypi\n",
      "termcolor                 1.1.0                    pypi_0    pypi\n",
      "threadpoolctl             3.0.0                    pypi_0    pypi\n",
      "tokenizers                0.10.3                   pypi_0    pypi\n",
      "torch                     1.9.1                    pypi_0    pypi\n",
      "tornado                   6.1              py39h2bbff1b_0  \n",
      "tqdm                      4.62.3                   pypi_0    pypi\n",
      "traitlets                 5.1.0              pyhd3eb1b0_0  \n",
      "transformers              4.11.3                   pypi_0    pypi\n",
      "typing-extensions         3.7.4.3                  pypi_0    pypi\n",
      "typing_extensions         3.10.0.2           pyh06a4308_0  \n",
      "tzdata                    2021a                h5d7bf9c_0  \n",
      "urllib3                   1.26.7                   pypi_0    pypi\n",
      "vc                        14.2                 h21ff451_1  \n",
      "vs2015_runtime            14.27.29016          h5e58377_2  \n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
      "werkzeug                  2.0.2                    pypi_0    pypi\n",
      "wheel                     0.35.1             pyhd3eb1b0_0  \n",
      "win_inet_pton             1.1.0            py39haa95532_0  \n",
      "wincertstore              0.2              py39haa95532_2  \n",
      "wrapt                     1.12.1           py39h196d8e1_1  \n",
      "yarl                      1.6.3            py39h2bbff1b_0  \n",
      "zipp                      3.6.0              pyhd3eb1b0_0  \n",
      "zlib                      1.2.11               h62dcd97_4  \n"
     ]
    }
   ],
   "source": [
    "!conda list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "import torch\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import transformers as ppb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(\"../../data/array_data_scibert.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle(\"../../data/array_data_scibert_prot4.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422      15.960649\n",
       "1190     15.273297\n",
       "1958     15.153947\n",
       "2726     15.898499\n",
       "3494     15.289441\n",
       "4262     15.623961\n",
       "4994      2.063572\n",
       "5030     16.016623\n",
       "5798     14.925836\n",
       "6566     15.593343\n",
       "7334     15.621113\n",
       "8102     15.613622\n",
       "8870     15.375978\n",
       "9638     16.531483\n",
       "10370     2.049575\n",
       "10406    15.744185\n",
       "11174    15.736642\n",
       "11942    15.883093\n",
       "12710    16.302942\n",
       "13478    16.083614\n",
       "14246    15.463799\n",
       "15014    15.688974\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[0][features.loc[0] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptpath = \"../scripts/\"\n",
    "\n",
    "# Add the directory containing your module to the Python path (wants absolute paths)\n",
    "sys.path.append(os.path.abspath(scriptpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import article_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ragou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def pre_processing(data):\n",
    "    # lowercase text\n",
    "    data = data.apply(lambda x: \" \".join(i.lower() for i in  str(x).split()))\n",
    "#     # remove numeric values\n",
    "#     data = data.str.replace(\"\\d\",\"\")\n",
    "#     # remove punctuations\n",
    "#     data = data.str.replace(\"[^\\w\\s]\",\"\")\n",
    "    # remove stopwords: the,a,an etc.\n",
    "    data = data.apply(lambda x: \" \".join(i for i in x.split() if i not in sw))\n",
    "    data = data.apply(lambda x: re.sub(\"\\.|,|\\)|\\(\",\"\",x))\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(text, size):\n",
    "    length_text = len(text)\n",
    "    final = []\n",
    "    for i in range(0, length_text, size):\n",
    "        final.append([\" \".join(text[i:i+size])])\n",
    "    return final\n",
    "\n",
    "\n",
    "def get_features(article, tokenizer):\n",
    "    token = []\n",
    "    max_len = 0\n",
    "    \n",
    "    for chunk in lemm(article):\n",
    "        token.append(tokenizer.encode(chunk, add_special_tokens=True))\n",
    "        \n",
    "    for i in token:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in token])\n",
    "        \n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    attention_mask.shape\n",
    "    \n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    \n",
    "    print(\"SHAPE\" ,features.shape)\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(features.T)\n",
    "    \n",
    "    return tsne_results.T.flatten()\n",
    "\n",
    "\n",
    "\n",
    "def lemm(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    temp = []\n",
    "    list_words = list(set(word_tokenize(text)))\n",
    "    for word in list_words:\n",
    "        temp.append(lemmatizer.lemmatize(word))\n",
    "    return list(set(temp))\n",
    "            \n",
    "def get_outlier(line):\n",
    "    length = lemm(line[\"Text\"])\n",
    "    \n",
    "    if length > 512:\n",
    "        return line[\"ID\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features([\"article\"], tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dtf = pd.read_csv(\"../datas/all_data_clean_011.txt\", sep = \"\\|\\|\", engine = \"python\")\n",
    "clean_dtf_one = pd.read_csv(\"../datas/all_data_clean_010.txt\", sep = \"\\|\\|\", engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_one = clean_dtf_one[\"Text\"]\n",
    "clean_text_one = pre_processing(text_one)\n",
    "clean_dtf_one[\"Text\"] = clean_text_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>truncating mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>mutations gene predict absence truncation cycl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>w802*</td>\n",
       "      <td>2</td>\n",
       "      <td>using select c-cbl somatic mutations s80n/h94y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>q249e</td>\n",
       "      <td>2</td>\n",
       "      <td>using select c-cbl somatic mutations s80n/h94y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>n454d</td>\n",
       "      <td>3</td>\n",
       "      <td>15 apart n454d residues affected missense muta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>l399v</td>\n",
       "      <td>4</td>\n",
       "      <td>finally third group constituted mutations l399...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3316</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>d171n</td>\n",
       "      <td>4</td>\n",
       "      <td>confirm involvement aml1 mutations hematopoiet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3317</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>a122*</td>\n",
       "      <td>1</td>\n",
       "      <td>histopathologic findings b spleen d liver f ki...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3318</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>fusions</td>\n",
       "      <td>1</td>\n",
       "      <td>out-of-frame fusions rhd runx1 retained early ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3319</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>r80c</td>\n",
       "      <td>4</td>\n",
       "      <td>runx1 mutants r80c k83n k83e showed strong aff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3320</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>k83e</td>\n",
       "      <td>4</td>\n",
       "      <td>electropherograms affected control individuals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    Gene             Variation  Class  \\\n",
       "0        0  FAM58A  truncating mutations      1   \n",
       "1        1     CBL                 w802*      2   \n",
       "2        2     CBL                 q249e      2   \n",
       "3        3     CBL                 n454d      3   \n",
       "4        4     CBL                 l399v      4   \n",
       "...    ...     ...                   ...    ...   \n",
       "3311  3316   RUNX1                 d171n      4   \n",
       "3312  3317   RUNX1                 a122*      1   \n",
       "3313  3318   RUNX1               fusions      1   \n",
       "3314  3319   RUNX1                  r80c      4   \n",
       "3315  3320   RUNX1                  k83e      4   \n",
       "\n",
       "                                                   Text  Score  \n",
       "0     mutations gene predict absence truncation cycl...      2  \n",
       "1     using select c-cbl somatic mutations s80n/h94y...      1  \n",
       "2     using select c-cbl somatic mutations s80n/h94y...      1  \n",
       "3     15 apart n454d residues affected missense muta...      1  \n",
       "4     finally third group constituted mutations l399...      1  \n",
       "...                                                 ...    ...  \n",
       "3311  confirm involvement aml1 mutations hematopoiet...      1  \n",
       "3312  histopathologic findings b spleen d liver f ki...      2  \n",
       "3313  out-of-frame fusions rhd runx1 retained early ...      1  \n",
       "3314  runx1 mutants r80c k83n k83e showed strong aff...      1  \n",
       "3315  electropherograms affected control individuals...      1  \n",
       "\n",
       "[3316 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dtf_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_dtf[\"Text\"]\n",
    "clean_text = pre_processing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>truncating mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>mutations in this gene that predict absence o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>w802*</td>\n",
       "      <td>2</td>\n",
       "      <td>using select c-cbl somatic mutations such as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>q249e</td>\n",
       "      <td>2</td>\n",
       "      <td>using select c-cbl somatic mutations such as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>n454d</td>\n",
       "      <td>3</td>\n",
       "      <td>15 apart from n454d, all residues affected by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>l399v</td>\n",
       "      <td>4</td>\n",
       "      <td>finally, the third group constituted mutatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3316</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>d171n</td>\n",
       "      <td>4</td>\n",
       "      <td>to confirm the involvement of aml1 mutations ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3317</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>a122*</td>\n",
       "      <td>1</td>\n",
       "      <td>histopathologic findings of (b) spleen, (d) l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3318</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>fusions</td>\n",
       "      <td>1</td>\n",
       "      <td>out-of-frame fusions, in which the rhd of run...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3319</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>r80c</td>\n",
       "      <td>4</td>\n",
       "      <td>these runx1 mutants, r80c, k83n, and k83e sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3320</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>k83e</td>\n",
       "      <td>4</td>\n",
       "      <td>electropherograms from affected and control in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    Gene             Variation  Class  \\\n",
       "0        0  FAM58A  truncating mutations      1   \n",
       "1        1     CBL                 w802*      2   \n",
       "2        2     CBL                 q249e      2   \n",
       "3        3     CBL                 n454d      3   \n",
       "4        4     CBL                 l399v      4   \n",
       "...    ...     ...                   ...    ...   \n",
       "3311  3316   RUNX1                 d171n      4   \n",
       "3312  3317   RUNX1                 a122*      1   \n",
       "3313  3318   RUNX1               fusions      1   \n",
       "3314  3319   RUNX1                  r80c      4   \n",
       "3315  3320   RUNX1                  k83e      4   \n",
       "\n",
       "                                                   Text  Score  \n",
       "0      mutations in this gene that predict absence o...      2  \n",
       "1      using select c-cbl somatic mutations such as ...      1  \n",
       "2      using select c-cbl somatic mutations such as ...      1  \n",
       "3     15 apart from n454d, all residues affected by ...      1  \n",
       "4       finally, the third group constituted mutatio...      1  \n",
       "...                                                 ...    ...  \n",
       "3311   to confirm the involvement of aml1 mutations ...      1  \n",
       "3312   histopathologic findings of (b) spleen, (d) l...      2  \n",
       "3313   out-of-frame fusions, in which the rhd of run...      1  \n",
       "3314   these runx1 mutants, r80c, k83n, and k83e sho...      1  \n",
       "3315  electropherograms from affected and control in...      1  \n",
       "\n",
       "[3316 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dtf[\"Text\"] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 968\n",
      "None\n",
      "213 3319\n",
      "None\n",
      "213 3319\n",
      "None\n",
      "125 1308\n",
      "None\n",
      "38 367\n",
      "None\n",
      "38 367\n",
      "None\n",
      "47 440\n",
      "None\n",
      "571 9164\n",
      "None\n",
      "481 12298\n",
      "None\n",
      "441 11659\n",
      "None\n",
      "38 367\n",
      "None\n",
      "403 7811\n",
      "None\n",
      "1003 23660\n",
      "None\n",
      "336 5375\n",
      "None\n",
      "30 227\n",
      "None\n",
      "348 7152\n",
      "None\n",
      "76 750\n",
      "None\n",
      "32 303\n",
      "None\n",
      "76 763\n",
      "None\n",
      "97 1136\n",
      "None\n",
      "261 4249\n",
      "None\n",
      "52 503\n",
      "None\n",
      "38 367\n",
      "None\n",
      "57 495\n",
      "None\n",
      "101 916\n",
      "None\n",
      "57 495\n",
      "None\n",
      "379 5458\n",
      "None\n",
      "432 7172\n",
      "None\n",
      "252 3086\n",
      "None\n",
      "432 7172\n",
      "None\n",
      "432 7172\n",
      "None\n",
      "1616 41346\n",
      "None\n",
      "432 7172\n",
      "None\n",
      "875 20932\n",
      "None\n",
      "810 18025\n",
      "None\n",
      "389 7111\n",
      "None\n",
      "93 1217\n",
      "None\n",
      "67 875\n",
      "None\n",
      "83 1150\n",
      "None\n",
      "62 816\n",
      "None\n",
      "62 816\n",
      "None\n",
      "83 1059\n",
      "None\n",
      "67 875\n",
      "None\n",
      "1076 22017\n",
      "None\n",
      "31 311\n",
      "None\n",
      "55 1368\n",
      "None\n",
      "474 7024\n",
      "None\n",
      "55 1368\n",
      "None\n",
      "1128 34655\n",
      "None\n",
      "31 311\n",
      "None\n",
      "97 1331\n",
      "None\n",
      "97 1331\n",
      "None\n",
      "406 7427\n",
      "None\n",
      "105 2023\n",
      "None\n",
      "97 1331\n",
      "None\n",
      "55 1368\n",
      "None\n",
      "79 961\n",
      "None\n",
      "91 1839\n",
      "None\n",
      "97 1331\n",
      "None\n",
      "55 542\n",
      "None\n",
      "106 2020\n",
      "None\n",
      "242 3841\n",
      "None\n",
      "77 787\n",
      "None\n",
      "151 1988\n",
      "None\n",
      "55 1368\n",
      "None\n",
      "89 1175\n",
      "None\n",
      "151 1988\n",
      "None\n",
      "721 14239\n",
      "None\n",
      "820 19899\n",
      "None\n",
      "721 14239\n",
      "None\n",
      "509 7284\n",
      "None\n",
      "23 214\n",
      "None\n",
      "116 1382\n",
      "None\n",
      "27 264\n",
      "None\n",
      "275 2890\n",
      "None\n",
      "23 214\n",
      "None\n",
      "38 315\n",
      "None\n",
      "55 504\n",
      "None\n",
      "249 3459\n",
      "None\n",
      "186 2151\n",
      "None\n",
      "62 612\n",
      "None\n",
      "38 315\n",
      "None\n",
      "62 519\n",
      "None\n",
      "29 247\n",
      "None\n",
      "438 7110\n",
      "None\n",
      "99 1107\n",
      "None\n",
      "703 16706\n",
      "None\n",
      "377 5757\n",
      "None\n",
      "34 304\n",
      "None\n",
      "225 2636\n",
      "None\n",
      "320 4288\n",
      "None\n",
      "205 2383\n",
      "None\n",
      "28 252\n",
      "None\n",
      "227 2659\n",
      "None\n",
      "96 1433\n",
      "None\n",
      "444 5047\n",
      "None\n",
      "946 23887\n",
      "None\n",
      "381 7024\n",
      "None\n",
      "539 12480\n",
      "None\n",
      "334 6495\n",
      "None\n",
      "453 11537\n",
      "None\n",
      "911 19451\n",
      "None\n",
      "181 2487\n",
      "None\n",
      "213 2600\n",
      "None\n",
      "28 293\n",
      "None\n",
      "432 3462\n",
      "None\n",
      "134 1398\n",
      "None\n",
      "750 14688\n",
      "None\n",
      "639 10207\n",
      "None\n",
      "550 5961\n",
      "None\n",
      "30 295\n",
      "None\n",
      "118 1365\n",
      "None\n",
      "75 762\n",
      "None\n",
      "190 2266\n",
      "None\n",
      "728 14184\n",
      "None\n",
      "569 8095\n",
      "None\n",
      "227 2973\n",
      "None\n",
      "328 4975\n",
      "None\n",
      "274 3862\n",
      "None\n",
      "368 4946\n",
      "None\n",
      "168 1992\n",
      "None\n",
      "208 3416\n",
      "None\n",
      "78 781\n",
      "None\n",
      "108 766\n",
      "None\n",
      "108 766\n",
      "None\n",
      "415 6049\n",
      "None\n",
      "415 6049\n",
      "None\n",
      "138 1063\n",
      "None\n",
      "82 763\n",
      "None\n",
      "191 2356\n",
      "None\n",
      "79 763\n",
      "None\n",
      "165 1284\n",
      "None\n",
      "78 1013\n",
      "None\n",
      "40 413\n",
      "None\n",
      "138 1063\n",
      "None\n",
      "1615 45690\n",
      "None\n",
      "23 178\n",
      "None\n",
      "367 7103\n",
      "None\n",
      "519 9337\n",
      "None\n",
      "1788 60415\n",
      "None\n",
      "114 2313\n",
      "None\n",
      "40 420\n",
      "None\n",
      "266 3955\n",
      "None\n",
      "354 8381\n",
      "None\n",
      "138 1888\n",
      "None\n",
      "114 2313\n",
      "None\n",
      "526 10541\n",
      "None\n",
      "1741 58505\n",
      "None\n",
      "411 7186\n",
      "None\n",
      "598 10218\n",
      "None\n",
      "1264 27577\n",
      "None\n",
      "88 1696\n",
      "None\n",
      "700 12641\n",
      "None\n",
      "22 171\n",
      "None\n",
      "460 8702\n",
      "None\n",
      "33 345\n",
      "None\n",
      "203 3198\n",
      "None\n",
      "188 2990\n",
      "None\n",
      "378 5281\n",
      "None\n",
      "49 583\n",
      "None\n",
      "641 12152\n",
      "None\n",
      "33 345\n",
      "None\n",
      "241 3632\n",
      "None\n",
      "145 1872\n",
      "None\n",
      "479 7222\n",
      "None\n",
      "411 7095\n",
      "None\n",
      "15 117\n",
      "None\n",
      "182 1769\n",
      "None\n",
      "44 482\n",
      "None\n",
      "1158 30712\n",
      "None\n",
      "79 1000\n",
      "None\n",
      "90 1141\n",
      "None\n",
      "307 5892\n",
      "None\n",
      "332 9042\n",
      "None\n",
      "502 8764\n",
      "None\n",
      "1788 60415\n",
      "None\n",
      "302 8062\n",
      "None\n",
      "188 2990\n",
      "None\n",
      "929 21732\n",
      "None\n",
      "142 1628\n",
      "None\n",
      "269 4352\n",
      "None\n",
      "89 1036\n",
      "None\n",
      "115 2120\n",
      "None\n",
      "188 2990\n",
      "None\n",
      "532 9664\n",
      "None\n",
      "50 666\n",
      "None\n",
      "62 749\n",
      "None\n",
      "704 14019\n",
      "None\n",
      "474 9314\n",
      "None\n",
      "643 13595\n",
      "None\n",
      "510 10257\n",
      "None\n",
      "141 1790\n",
      "None\n",
      "86 948\n",
      "None\n",
      "1762 59441\n",
      "None\n",
      "92 1204\n",
      "None\n",
      "656 12543\n",
      "None\n",
      "161 2374\n",
      "None\n",
      "1295 33859\n",
      "None\n",
      "358 6005\n",
      "None\n",
      "207 3602\n",
      "None\n",
      "1030 28011\n",
      "None\n",
      "291 3139\n",
      "None\n",
      "103 1173\n",
      "None\n",
      "28 325\n",
      "None\n",
      "694 12590\n",
      "None\n",
      "137 1856\n",
      "None\n",
      "772 17405\n",
      "None\n",
      "191 2287\n",
      "None\n",
      "44 558\n",
      "None\n",
      "115 1229\n",
      "None\n",
      "456 7482\n",
      "None\n",
      "541 10518\n",
      "None\n",
      "633 12145\n",
      "None\n",
      "44 558\n",
      "None\n",
      "92 1204\n",
      "None\n",
      "44 558\n",
      "None\n",
      "27 207\n",
      "None\n",
      "29 255\n",
      "None\n",
      "546 10523\n",
      "None\n",
      "634 12461\n",
      "None\n",
      "287 4513\n",
      "None\n",
      "541 9949\n",
      "None\n",
      "47 470\n",
      "None\n",
      "326 4560\n",
      "None\n",
      "95 1203\n",
      "None\n",
      "356 7755\n",
      "None\n",
      "413 6905\n",
      "None\n",
      "185 2645\n",
      "None\n",
      "153 1661\n",
      "None\n",
      "649 12051\n",
      "None\n",
      "422 7385\n",
      "None\n",
      "593 10674\n",
      "None\n",
      "598 10218\n",
      "None\n",
      "222 2719\n",
      "None\n",
      "141 1790\n",
      "None\n",
      "980 24745\n",
      "None\n",
      "400 6692\n",
      "None\n",
      "46 610\n",
      "None\n",
      "673 13878\n",
      "None\n",
      "133 1526\n",
      "None\n",
      "606 11819\n",
      "None\n",
      "49 457\n",
      "None\n",
      "289 3860\n",
      "None\n",
      "171 2148\n",
      "None\n",
      "49 457\n",
      "None\n",
      "416 6960\n",
      "None\n",
      "79 913\n",
      "None\n",
      "139 1899\n",
      "None\n",
      "1741 58505\n",
      "None\n",
      "479 9420\n",
      "None\n",
      "105 1366\n",
      "None\n",
      "305 5419\n",
      "None\n",
      "316 4916\n",
      "None\n",
      "44 449\n",
      "None\n",
      "49 457\n",
      "None\n",
      "635 15026\n",
      "None\n",
      "206 3087\n",
      "None\n",
      "327 4803\n",
      "None\n",
      "315 4742\n",
      "None\n",
      "114 2313\n",
      "None\n",
      "241 5333\n",
      "None\n",
      "1813 61792\n",
      "None\n",
      "519 9337\n",
      "None\n",
      "81 944\n",
      "None\n",
      "243 4303\n",
      "None\n",
      "605 11625\n",
      "None\n",
      "594 12950\n",
      "None\n",
      "756 19058\n",
      "None\n",
      "479 7222\n",
      "None\n",
      "188 2990\n",
      "None\n",
      "473 8319\n",
      "None\n",
      "37 324\n",
      "None\n",
      "518 9677\n",
      "None\n",
      "145 1569\n",
      "None\n",
      "120 1508\n",
      "None\n",
      "44 558\n",
      "None\n",
      "593 10674\n",
      "None\n",
      "934 24070\n",
      "None\n",
      "101 1057\n",
      "None\n",
      "96 1053\n",
      "None\n",
      "96 1053\n",
      "None\n",
      "832 16548\n",
      "None\n",
      "23 193\n",
      "None\n",
      "96 1053\n",
      "None\n",
      "804 20659\n",
      "None\n",
      "53 580\n",
      "None\n",
      "212 2503\n",
      "None\n",
      "74 835\n",
      "None\n",
      "112 1316\n",
      "None\n",
      "232 3377\n",
      "None\n",
      "112 1640\n",
      "None\n",
      "350 5471\n",
      "None\n",
      "401 7934\n",
      "None\n",
      "1141 29183\n",
      "None\n",
      "27 250\n",
      "None\n",
      "262 4185\n",
      "None\n",
      "430 8724\n",
      "None\n",
      "363 5981\n",
      "None\n",
      "168 2009\n",
      "None\n",
      "608 12509\n",
      "None\n",
      "38 389\n",
      "None\n",
      "347 7381\n",
      "None\n",
      "346 6461\n",
      "None\n",
      "75 789\n",
      "None\n",
      "432 8427\n",
      "None\n",
      "274 5103\n",
      "None\n",
      "141 1318\n",
      "None\n",
      "83 663\n",
      "None\n",
      "141 1318\n",
      "None\n",
      "97 969\n",
      "None\n",
      "67 678\n",
      "None\n",
      "36 284\n",
      "None\n",
      "36 284\n",
      "None\n",
      "159 2098\n",
      "None\n",
      "95 930\n",
      "None\n",
      "272 4289\n",
      "None\n",
      "103 997\n",
      "None\n",
      "630 10896\n",
      "None\n",
      "412 6374\n",
      "None\n",
      "549 9540\n",
      "None\n",
      "67 639\n",
      "None\n",
      "1100 26424\n",
      "None\n",
      "231 3289\n",
      "None\n",
      "92 936\n",
      "None\n",
      "843 23707\n",
      "None\n",
      "61 606\n",
      "None\n",
      "66 681\n",
      "None\n",
      "110 1573\n",
      "None\n",
      "141 2282\n",
      "None\n",
      "231 3289\n",
      "None\n",
      "377 6128\n",
      "None\n",
      "549 9540\n",
      "None\n",
      "549 9540\n",
      "None\n",
      "61 598\n",
      "None\n",
      "95 1440\n",
      "None\n",
      "1558 42938\n",
      "None\n",
      "156 2309\n",
      "None\n",
      "34 309\n",
      "None\n",
      "883 19510\n",
      "None\n",
      "38 306\n",
      "None\n",
      "701 10145\n",
      "None\n",
      "31 326\n",
      "None\n",
      "288 3974\n",
      "None\n",
      "889 20202\n",
      "None\n",
      "86 1050\n",
      "None\n",
      "42 383\n",
      "None\n",
      "86 1050\n",
      "None\n",
      "190 2055\n",
      "None\n",
      "86 1050\n",
      "None\n",
      "115 1314\n",
      "None\n",
      "224 4838\n",
      "None\n",
      "559 12557\n",
      "None\n",
      "66 619\n",
      "None\n",
      "71 751\n",
      "None\n",
      "86 877\n",
      "None\n",
      "695 11869\n",
      "None\n",
      "384 6185\n",
      "None\n",
      "309 7173\n",
      "None\n",
      "590 10087\n",
      "None\n",
      "275 4026\n",
      "None\n",
      "71 751\n",
      "None\n",
      "86 996\n",
      "None\n",
      "128 1352\n",
      "None\n",
      "168 1933\n",
      "None\n",
      "128 1352\n",
      "None\n",
      "178 2194\n",
      "None\n",
      "129 1453\n",
      "None\n",
      "576 11380\n",
      "None\n",
      "86 996\n",
      "None\n",
      "241 4390\n",
      "None\n",
      "262 3183\n",
      "None\n",
      "272 4677\n",
      "None\n",
      "78 989\n",
      "None\n",
      "253 3606\n",
      "None\n",
      "172 2780\n",
      "None\n",
      "324 5427\n",
      "None\n",
      "189 2653\n",
      "None\n",
      "128 2062\n",
      "None\n",
      "61 583\n",
      "None\n",
      "25 230\n",
      "None\n",
      "196 3691\n",
      "None\n",
      "250 3217\n",
      "None\n",
      "103 950\n",
      "None\n",
      "581 14464\n",
      "None\n",
      "104 1218\n",
      "None\n",
      "158 2008\n",
      "None\n",
      "489 9830\n",
      "None\n",
      "67 708\n",
      "None\n",
      "45 407\n",
      "None\n",
      "73 755\n",
      "None\n",
      "409 5396\n",
      "None\n",
      "42 409\n",
      "None\n",
      "72 722\n",
      "None\n",
      "281 3655\n",
      "None\n",
      "96 1520\n",
      "None\n",
      "485 9166\n",
      "None\n",
      "784 13930\n",
      "None\n",
      "72 722\n",
      "None\n",
      "193 3095\n",
      "None\n",
      "111 1315\n",
      "None\n",
      "491 8213\n",
      "None\n",
      "42 409\n",
      "None\n",
      "103 950\n",
      "None\n",
      "585 10173\n",
      "None\n",
      "199 2574\n",
      "None\n",
      "23 188\n",
      "None\n",
      "50 439\n",
      "None\n",
      "192 2417\n",
      "None\n",
      "32 279\n",
      "None\n",
      "30 276\n",
      "None\n",
      "73 755\n",
      "None\n",
      "207 3253\n",
      "None\n",
      "71 692\n",
      "None\n",
      "91 1101\n",
      "None\n",
      "118 1406\n",
      "None\n",
      "155 1955\n",
      "None\n",
      "94 3126\n",
      "None\n",
      "683 13856\n",
      "None\n",
      "189 2105\n",
      "None\n",
      "171 3011\n",
      "None\n",
      "182 2782\n",
      "None\n",
      "108 1566\n",
      "None\n",
      "201 2604\n",
      "None\n",
      "233 3882\n",
      "None\n",
      "259 4913\n",
      "None\n",
      "114 1288\n",
      "None\n",
      "276 4419\n",
      "None\n",
      "141 1729\n",
      "None\n",
      "71 692\n",
      "None\n",
      "306 6509\n",
      "None\n",
      "27 248\n",
      "None\n",
      "566 8662\n",
      "None\n",
      "332 7454\n",
      "None\n",
      "426 10045\n",
      "None\n",
      "246 3481\n",
      "None\n",
      "1188 32267\n",
      "None\n",
      "85 1191\n",
      "None\n",
      "88 957\n",
      "None\n",
      "47 424\n",
      "None\n",
      "161 2128\n",
      "None\n",
      "76 750\n",
      "None\n",
      "135 1848\n",
      "None\n",
      "141 1745\n",
      "None\n",
      "69 814\n",
      "None\n",
      "250 3065\n",
      "None\n",
      "85 1191\n",
      "None\n",
      "68 654\n",
      "None\n",
      "19 173\n",
      "None\n",
      "126 1534\n",
      "None\n",
      "31 214\n",
      "None\n",
      "281 3252\n",
      "None\n",
      "85 1191\n",
      "None\n",
      "47 424\n",
      "None\n",
      "572 11658\n",
      "None\n",
      "293 4376\n",
      "None\n",
      "67 624\n",
      "None\n",
      "44 347\n",
      "None\n",
      "424 5534\n",
      "None\n",
      "156 1553\n",
      "None\n",
      "18 132\n",
      "None\n",
      "160 2123\n",
      "None\n",
      "97 1178\n",
      "None\n",
      "157 1962\n",
      "None\n",
      "409 6540\n",
      "None\n",
      "33 226\n",
      "None\n",
      "50 641\n",
      "None\n",
      "29 266\n",
      "None\n",
      "71 597\n",
      "None\n",
      "70 759\n",
      "None\n",
      "61 607\n",
      "None\n",
      "333 5116\n",
      "None\n",
      "207 2535\n",
      "None\n",
      "160 1931\n",
      "None\n",
      "431 8249\n",
      "None\n",
      "24 202\n",
      "None\n",
      "47 424\n",
      "None\n",
      "68 610\n",
      "None\n",
      "595 13493\n",
      "None\n",
      "61 607\n",
      "None\n",
      "192 2417\n",
      "None\n",
      "176 1810\n",
      "None\n",
      "77 906\n",
      "None\n",
      "47 424\n",
      "None\n",
      "29 250\n",
      "None\n",
      "153 2602\n",
      "None\n",
      "63 816\n",
      "None\n",
      "29 262\n",
      "None\n",
      "27 218\n",
      "None\n",
      "135 1774\n",
      "None\n",
      "264 5768\n",
      "None\n",
      "70 759\n",
      "None\n",
      "163 1982\n",
      "None\n",
      "204 2287\n",
      "None\n",
      "42 409\n",
      "None\n",
      "225 2198\n",
      "None\n",
      "272 4556\n",
      "None\n",
      "323 5071\n",
      "None\n",
      "85 1191\n",
      "None\n",
      "34 271\n",
      "None\n",
      "97 1178\n",
      "None\n",
      "186 2453\n",
      "None\n",
      "16 128\n",
      "None\n",
      "50 439\n",
      "None\n",
      "42 409\n",
      "None\n",
      "383 6296\n",
      "None\n",
      "166 2586\n",
      "None\n",
      "71 828\n",
      "None\n",
      "707 15017\n",
      "None\n",
      "42 409\n",
      "None\n",
      "279 4294\n",
      "None\n",
      "729 17848\n",
      "None\n",
      "303 4597\n",
      "None\n",
      "76 989\n",
      "None\n",
      "74 1088\n",
      "None\n",
      "72 722\n",
      "None\n",
      "28 237\n",
      "None\n",
      "30 215\n",
      "None\n",
      "143 2366\n",
      "None\n",
      "77 814\n",
      "None\n",
      "532 10497\n",
      "None\n",
      "67 624\n",
      "None\n",
      "33 226\n",
      "None\n",
      "78 1011\n",
      "None\n",
      "136 1832\n",
      "None\n",
      "85 769\n",
      "None\n",
      "272 3985\n",
      "None\n",
      "85 1191\n",
      "None\n",
      "87 1051\n",
      "None\n",
      "84 863\n",
      "None\n",
      "64 549\n",
      "None\n",
      "91 1015\n",
      "None\n",
      "74 680\n",
      "None\n",
      "30 299\n",
      "None\n",
      "144 1533\n",
      "None\n",
      "71 727\n",
      "None\n",
      "78 748\n",
      "None\n",
      "24 287\n",
      "None\n",
      "27 234\n",
      "None\n",
      "81 1111\n",
      "None\n",
      "643 12774\n",
      "None\n",
      "78 748\n",
      "None\n",
      "64 823\n",
      "None\n",
      "76 949\n",
      "None\n",
      "78 748\n",
      "None\n",
      "95 1005\n",
      "None\n",
      "124 1748\n",
      "None\n",
      "107 1492\n",
      "None\n",
      "64 823\n",
      "None\n",
      "92 1162\n",
      "None\n",
      "64 823\n",
      "None\n",
      "78 748\n",
      "None\n",
      "65 702\n",
      "None\n",
      "80 1045\n",
      "None\n",
      "248 1966\n",
      "None\n",
      "396 5432\n",
      "None\n",
      "405 5266\n",
      "None\n",
      "72 584\n",
      "None\n",
      "285 4604\n",
      "None\n",
      "202 2776\n",
      "None\n",
      "248 3118\n",
      "None\n",
      "404 5835\n",
      "None\n",
      "100 777\n",
      "None\n",
      "100 777\n",
      "None\n",
      "72 584\n",
      "None\n",
      "126 1082\n",
      "None\n",
      "337 6226\n",
      "None\n",
      "72 584\n",
      "None\n",
      "100 777\n",
      "None\n",
      "461 6764\n",
      "None\n",
      "250 3567\n",
      "None\n",
      "100 777\n",
      "None\n",
      "31 289\n",
      "None\n",
      "44 455\n",
      "None\n",
      "107 1028\n",
      "None\n",
      "220 2961\n",
      "None\n",
      "72 584\n",
      "None\n",
      "34 327\n",
      "None\n",
      "41 363\n",
      "None\n",
      "197 3053\n",
      "None\n",
      "268 4395\n",
      "None\n",
      "98 1211\n",
      "None\n",
      "448 7697\n",
      "None\n",
      "219 3345\n",
      "None\n",
      "169 2336\n",
      "None\n",
      "27 240\n",
      "None\n",
      "63 581\n",
      "None\n",
      "330 6978\n",
      "None\n",
      "239 4177\n",
      "None\n",
      "24 287\n",
      "None\n",
      "106 1556\n",
      "None\n",
      "81 1111\n",
      "None\n",
      "64 823\n",
      "None\n",
      "41 363\n",
      "None\n",
      "448 7697\n",
      "None\n",
      "117 1499\n",
      "None\n",
      "144 1966\n",
      "None\n",
      "56 439\n",
      "None\n",
      "1194 28136\n",
      "None\n",
      "64 823\n",
      "None\n",
      "41 363\n",
      "None\n",
      "64 823\n",
      "None\n",
      "106 1556\n",
      "None\n",
      "59 946\n",
      "None\n",
      "713 19662\n",
      "None\n",
      "281 3759\n",
      "None\n",
      "419 7014\n",
      "None\n",
      "72 723\n",
      "None\n",
      "341 6542\n",
      "None\n",
      "59 578\n",
      "None\n",
      "232 2540\n",
      "None\n",
      "1027 27849\n",
      "None\n",
      "227 2599\n",
      "None\n",
      "187 2380\n",
      "None\n",
      "173 2387\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052 21656\n",
      "None\n",
      "210 2231\n",
      "None\n",
      "23 165\n",
      "None\n",
      "30 307\n",
      "None\n",
      "66 706\n",
      "None\n",
      "270 4830\n",
      "None\n",
      "57 474\n",
      "None\n",
      "234 2571\n",
      "None\n",
      "101 1073\n",
      "None\n",
      "66 706\n",
      "None\n",
      "245 2597\n",
      "None\n",
      "66 706\n",
      "None\n",
      "246 3910\n",
      "None\n",
      "138 2122\n",
      "None\n",
      "26 265\n",
      "None\n",
      "537 9627\n",
      "None\n",
      "66 706\n",
      "None\n",
      "91 1142\n",
      "None\n",
      "295 3925\n",
      "None\n",
      "524 11239\n",
      "None\n",
      "139 1633\n",
      "None\n",
      "543 10972\n",
      "None\n",
      "34 341\n",
      "None\n",
      "773 14087\n",
      "None\n",
      "638 12683\n",
      "None\n",
      "196 2308\n",
      "None\n",
      "334 6603\n",
      "None\n",
      "185 2011\n",
      "None\n",
      "194 2546\n",
      "None\n",
      "257 3249\n",
      "None\n",
      "151 3266\n",
      "None\n",
      "165 3248\n",
      "None\n",
      "151 3266\n",
      "None\n",
      "136 1970\n",
      "None\n",
      "55 557\n",
      "None\n",
      "202 3890\n",
      "None\n",
      "83 876\n",
      "None\n",
      "399 5266\n",
      "None\n",
      "236 4262\n",
      "None\n",
      "32 223\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "165 3248\n",
      "None\n",
      "47 459\n",
      "None\n",
      "47 459\n",
      "None\n",
      "148 2054\n",
      "None\n",
      "57 703\n",
      "None\n",
      "57 703\n",
      "None\n",
      "210 3062\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "64 618\n",
      "None\n",
      "505 9231\n",
      "None\n",
      "158 3180\n",
      "None\n",
      "74 668\n",
      "None\n",
      "165 3248\n",
      "None\n",
      "412 7535\n",
      "None\n",
      "151 3266\n",
      "None\n",
      "305 4067\n",
      "None\n",
      "151 3266\n",
      "None\n",
      "47 459\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "476 7425\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "94 1296\n",
      "None\n",
      "86 974\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "580 9772\n",
      "None\n",
      "508 8299\n",
      "None\n",
      "112 1558\n",
      "None\n",
      "102 1007\n",
      "None\n",
      "287 3371\n",
      "None\n",
      "189 1866\n",
      "None\n",
      "138 2962\n",
      "None\n",
      "151 3266\n",
      "None\n",
      "172 3480\n",
      "None\n",
      "113 1217\n",
      "None\n",
      "452 7674\n",
      "None\n",
      "187 2593\n",
      "None\n",
      "35 276\n",
      "None\n",
      "113 1217\n",
      "None\n",
      "113 1217\n",
      "None\n",
      "54 527\n",
      "None\n",
      "387 5119\n",
      "None\n",
      "1624 46022\n",
      "None\n",
      "141 1923\n",
      "None\n",
      "56 1105\n",
      "None\n",
      "156 2116\n",
      "None\n",
      "56 1105\n",
      "None\n",
      "922 23285\n",
      "None\n",
      "779 16342\n",
      "None\n",
      "30 281\n",
      "None\n",
      "100 883\n",
      "None\n",
      "136 1647\n",
      "None\n",
      "232 3646\n",
      "None\n",
      "198 2871\n",
      "None\n",
      "39 242\n",
      "None\n",
      "82 778\n",
      "None\n",
      "226 3577\n",
      "None\n",
      "115 1597\n",
      "None\n",
      "30 281\n",
      "None\n",
      "773 16294\n",
      "None\n",
      "30 281\n",
      "None\n",
      "30 281\n",
      "None\n",
      "276 5257\n",
      "None\n",
      "30 281\n",
      "None\n",
      "25 234\n",
      "None\n",
      "103 1293\n",
      "None\n",
      "386 6104\n",
      "None\n",
      "55 622\n",
      "None\n",
      "162 2652\n",
      "None\n",
      "226 3577\n",
      "None\n",
      "81 780\n",
      "None\n",
      "64 550\n",
      "None\n",
      "229 3374\n",
      "None\n",
      "40 347\n",
      "None\n",
      "308 6334\n",
      "None\n",
      "188 2289\n",
      "None\n",
      "282 3468\n",
      "None\n",
      "282 3468\n",
      "None\n",
      "756 14851\n",
      "None\n",
      "58 688\n",
      "None\n",
      "30 281\n",
      "None\n",
      "116 2006\n",
      "None\n",
      "188 2838\n",
      "None\n",
      "95 1031\n",
      "None\n",
      "155 2115\n",
      "None\n",
      "85 991\n",
      "None\n",
      "303 4236\n",
      "None\n",
      "38 348\n",
      "None\n",
      "514 10287\n",
      "None\n",
      "139 1895\n",
      "None\n",
      "894 18052\n",
      "None\n",
      "558 11168\n",
      "None\n",
      "48 514\n",
      "None\n",
      "233 2851\n",
      "None\n",
      "52 451\n",
      "None\n",
      "115 1153\n",
      "None\n",
      "781 18704\n",
      "None\n",
      "207 3085\n",
      "None\n",
      "39 242\n",
      "None\n",
      "86 1039\n",
      "None\n",
      "410 6007\n",
      "None\n",
      "54 632\n",
      "None\n",
      "79 1044\n",
      "None\n",
      "81 780\n",
      "None\n",
      "64 550\n",
      "None\n",
      "71 875\n",
      "None\n",
      "37 375\n",
      "None\n",
      "168 2189\n",
      "None\n",
      "74 667\n",
      "None\n",
      "588 10098\n",
      "None\n",
      "25 189\n",
      "None\n",
      "30 281\n",
      "None\n",
      "58 688\n",
      "None\n",
      "46 446\n",
      "None\n",
      "123 1437\n",
      "None\n",
      "140 1681\n",
      "None\n",
      "188 2711\n",
      "None\n",
      "391 7042\n",
      "None\n",
      "132 1536\n",
      "None\n",
      "42 474\n",
      "None\n",
      "173 2817\n",
      "None\n",
      "105 1348\n",
      "None\n",
      "66 747\n",
      "None\n",
      "68 719\n",
      "None\n",
      "291 5031\n",
      "None\n",
      "253 4745\n",
      "None\n",
      "42 474\n",
      "None\n",
      "95 1270\n",
      "None\n",
      "107 1301\n",
      "None\n",
      "151 1936\n",
      "None\n",
      "58 604\n",
      "None\n",
      "46 654\n",
      "None\n",
      "117 1442\n",
      "None\n",
      "29 305\n",
      "None\n",
      "29 305\n",
      "None\n",
      "298 5752\n",
      "None\n",
      "117 1442\n",
      "None\n",
      "43 386\n",
      "None\n",
      "286 5623\n",
      "None\n",
      "353 5795\n",
      "None\n",
      "29 305\n",
      "None\n",
      "69 726\n",
      "None\n",
      "43 386\n",
      "None\n",
      "87 857\n",
      "None\n",
      "170 2280\n",
      "None\n",
      "160 2126\n",
      "None\n",
      "160 2126\n",
      "None\n",
      "285 5460\n",
      "None\n",
      "117 1442\n",
      "None\n",
      "25 220\n",
      "None\n",
      "25 220\n",
      "None\n",
      "32 275\n",
      "None\n",
      "25 220\n",
      "None\n",
      "713 15741\n",
      "None\n",
      "105 1065\n",
      "None\n",
      "31 269\n",
      "None\n",
      "29 261\n",
      "None\n",
      "45 385\n",
      "None\n",
      "43 413\n",
      "None\n",
      "92 945\n",
      "None\n",
      "25 220\n",
      "None\n",
      "43 413\n",
      "None\n",
      "81 599\n",
      "None\n",
      "81 760\n",
      "None\n",
      "173 1899\n",
      "None\n",
      "105 1065\n",
      "None\n",
      "23 242\n",
      "None\n",
      "43 413\n",
      "None\n",
      "798 21502\n",
      "None\n",
      "280 3836\n",
      "None\n",
      "627 12952\n",
      "None\n",
      "557 7812\n",
      "None\n",
      "169 2384\n",
      "None\n",
      "193 2322\n",
      "None\n",
      "366 5425\n",
      "None\n",
      "64 600\n",
      "None\n",
      "321 4214\n",
      "None\n",
      "379 5449\n",
      "None\n",
      "153 1636\n",
      "None\n",
      "24 213\n",
      "None\n",
      "194 2481\n",
      "None\n",
      "90 899\n",
      "None\n",
      "128 1348\n",
      "None\n",
      "168 2165\n",
      "None\n",
      "67 670\n",
      "None\n",
      "97 976\n",
      "None\n",
      "97 976\n",
      "None\n",
      "115 1128\n",
      "None\n",
      "63 652\n",
      "None\n",
      "67 670\n",
      "None\n",
      "26 182\n",
      "None\n",
      "266 4952\n",
      "None\n",
      "67 670\n",
      "None\n",
      "369 6469\n",
      "None\n",
      "362 5351\n",
      "None\n",
      "67 670\n",
      "None\n",
      "67 670\n",
      "None\n",
      "262 5193\n",
      "None\n",
      "189 2391\n",
      "None\n",
      "471 9451\n",
      "None\n",
      "250 3829\n",
      "None\n",
      "67 670\n",
      "None\n",
      "67 670\n",
      "None\n",
      "135 1432\n",
      "None\n",
      "83 986\n",
      "None\n",
      "107 1127\n",
      "None\n",
      "134 1561\n",
      "None\n",
      "97 976\n",
      "None\n",
      "22 245\n",
      "None\n",
      "79 906\n",
      "None\n",
      "733 14241\n",
      "None\n",
      "575 9230\n",
      "None\n",
      "42 410\n",
      "None\n",
      "759 13405\n",
      "None\n",
      "89 961\n",
      "None\n",
      "62 673\n",
      "None\n",
      "85 871\n",
      "None\n",
      "216 3097\n",
      "None\n",
      "35 392\n",
      "None\n",
      "152 2596\n",
      "None\n",
      "111 1589\n",
      "None\n",
      "73 815\n",
      "None\n",
      "896 22268\n",
      "None\n",
      "23 196\n",
      "None\n",
      "25 245\n",
      "None\n",
      "497 9858\n",
      "None\n",
      "117 1681\n",
      "None\n",
      "216 3097\n",
      "None\n",
      "148 2108\n",
      "None\n",
      "152 2596\n",
      "None\n",
      "283 5053\n",
      "None\n",
      "39 412\n",
      "None\n",
      "70 907\n",
      "None\n",
      "377 5824\n",
      "None\n",
      "80 759\n",
      "None\n",
      "193 3136\n",
      "None\n",
      "471 9538\n",
      "None\n",
      "73 815\n",
      "None\n",
      "35 392\n",
      "None\n",
      "147 1889\n",
      "None\n",
      "152 2596\n",
      "None\n",
      "541 11397\n",
      "None\n",
      "75 894\n",
      "None\n",
      "44 552\n",
      "None\n",
      "39 412\n",
      "None\n",
      "152 2204\n",
      "None\n",
      "147 1889\n",
      "None\n",
      "179 2879\n",
      "None\n",
      "148 2108\n",
      "None\n",
      "165 1902\n",
      "None\n",
      "302 5094\n",
      "None\n",
      "39 412\n",
      "None\n",
      "73 815\n",
      "None\n",
      "103 1443\n",
      "None\n",
      "1548 52131\n",
      "None\n",
      "103 1485\n",
      "None\n",
      "103 1443\n",
      "None\n",
      "216 3097\n",
      "None\n",
      "1187 25335\n",
      "None\n",
      "225 2841\n",
      "None\n",
      "262 4010\n",
      "None\n",
      "98 1191\n",
      "None\n",
      "152 2204\n",
      "None\n",
      "181 2871\n",
      "None\n",
      "297 5071\n",
      "None\n",
      "564 12865\n",
      "None\n",
      "216 3097\n",
      "None\n",
      "265 4094\n",
      "None\n",
      "48 450\n",
      "None\n",
      "271 4535\n",
      "None\n",
      "178 2555\n",
      "None\n",
      "155 2097\n",
      "None\n",
      "152 2204\n",
      "None\n",
      "95 1090\n",
      "None\n",
      "123 1809\n",
      "None\n",
      "216 3097\n",
      "None\n",
      "145 1940\n",
      "None\n",
      "200 2791\n",
      "None\n",
      "399 6155\n",
      "None\n",
      "355 4888\n",
      "None\n",
      "41 486\n",
      "None\n",
      "38 361\n",
      "None\n",
      "336 5190\n",
      "None\n",
      "83 1035\n",
      "None\n",
      "351 4544\n",
      "None\n",
      "67 749\n",
      "None\n",
      "231 2848\n",
      "None\n",
      "62 620\n",
      "None\n",
      "421 7463\n",
      "None\n",
      "341 4929\n",
      "None\n",
      "9 90\n",
      "None\n",
      "49 453\n",
      "None\n",
      "132 1604\n",
      "None\n",
      "817 16039\n",
      "None\n",
      "98 1124\n",
      "None\n",
      "192 2108\n",
      "None\n",
      "344 5290\n",
      "None\n",
      "102 1095\n",
      "None\n",
      "534 9238\n",
      "None\n",
      "275 4018\n",
      "None\n",
      "51 546\n",
      "None\n",
      "229 2992\n",
      "None\n",
      "104 1363\n",
      "None\n",
      "262 4908\n",
      "None\n",
      "280 5133\n",
      "None\n",
      "66 674\n",
      "None\n",
      "52 544\n",
      "None\n",
      "305 5540\n",
      "None\n",
      "420 6583\n",
      "None\n",
      "134 1847\n",
      "None\n",
      "797 20904\n",
      "None\n",
      "23 190\n",
      "None\n",
      "155 2393\n",
      "None\n",
      "568 13210\n",
      "None\n",
      "354 5266\n",
      "None\n",
      "208 2496\n",
      "None\n",
      "88 1017\n",
      "None\n",
      "155 2469\n",
      "None\n",
      "58 565\n",
      "None\n",
      "232 3074\n",
      "None\n",
      "38 328\n",
      "None\n",
      "134 1847\n",
      "None\n",
      "187 2471\n",
      "None\n",
      "1588 52710\n",
      "None\n",
      "38 389\n",
      "None\n",
      "877 17730\n",
      "None\n",
      "572 9135\n",
      "None\n",
      "172 2174\n",
      "None\n",
      "152 1556\n",
      "None\n",
      "218 2712\n",
      "None\n",
      "197 2433\n",
      "None\n",
      "173 1890\n",
      "None\n",
      "135 1644\n",
      "None\n",
      "295 4325\n",
      "None\n",
      "40 366\n",
      "None\n",
      "179 3075\n",
      "None\n",
      "102 1451\n",
      "None\n",
      "40 328\n",
      "None\n",
      "26 203\n",
      "None\n",
      "206 3554\n",
      "None\n",
      "26 203\n",
      "None\n",
      "168 2923\n",
      "None\n",
      "47 412\n",
      "None\n",
      "169 2933\n",
      "None\n",
      "419 7228\n",
      "None\n",
      "279 3344\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "995    None\n",
       "996    None\n",
       "997    None\n",
       "998    None\n",
       "999    None\n",
       "Name: Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text.apply(lambda x: print(lemm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "poubelle = clean_dtf_one.apply(lambda line: get_outlier(line), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_drop = poubelle.dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12        12\n",
       "31        31\n",
       "33        33\n",
       "34        34\n",
       "43        43\n",
       "        ... \n",
       "3242    3247\n",
       "3249    3254\n",
       "3291    3296\n",
       "3298    3303\n",
       "3311    3316\n",
       "Length: 224, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as px\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemm(clean_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE (84, 768)\n",
      "SHAPE (213, 768)\n",
      "SHAPE (213, 768)\n",
      "SHAPE (125, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (47, 768)\n",
      "SHAPE (571, 768)\n",
      "SHAPE (481, 768)\n",
      "SHAPE (441, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (403, 768)\n",
      "SHAPE (1003, 768)\n",
      "SHAPE (336, 768)\n",
      "SHAPE (30, 768)\n",
      "SHAPE (348, 768)\n",
      "SHAPE (76, 768)\n",
      "SHAPE (32, 768)\n",
      "SHAPE (76, 768)\n",
      "SHAPE (97, 768)\n",
      "SHAPE (261, 768)\n",
      "SHAPE (52, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (57, 768)\n",
      "SHAPE (101, 768)\n",
      "SHAPE (57, 768)\n",
      "SHAPE (379, 768)\n",
      "SHAPE (432, 768)\n",
      "SHAPE (252, 768)\n",
      "SHAPE (432, 768)\n",
      "SHAPE (432, 768)\n",
      "SHAPE (1616, 768)\n",
      "SHAPE (432, 768)\n",
      "SHAPE (875, 768)\n",
      "SHAPE (810, 768)\n",
      "SHAPE (389, 768)\n",
      "SHAPE (93, 768)\n",
      "SHAPE (67, 768)\n",
      "SHAPE (83, 768)\n",
      "SHAPE (62, 768)\n",
      "SHAPE (62, 768)\n",
      "SHAPE (83, 768)\n",
      "SHAPE (67, 768)\n",
      "SHAPE (1076, 768)\n",
      "SHAPE (31, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (474, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (1128, 768)\n",
      "SHAPE (31, 768)\n",
      "SHAPE (97, 768)\n",
      "SHAPE (97, 768)\n",
      "SHAPE (406, 768)\n",
      "SHAPE (105, 768)\n",
      "SHAPE (97, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (79, 768)\n",
      "SHAPE (91, 768)\n",
      "SHAPE (97, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (106, 768)\n",
      "SHAPE (242, 768)\n",
      "SHAPE (77, 768)\n",
      "SHAPE (151, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (89, 768)\n",
      "SHAPE (151, 768)\n",
      "SHAPE (721, 768)\n",
      "SHAPE (820, 768)\n",
      "SHAPE (721, 768)\n",
      "SHAPE (509, 768)\n",
      "SHAPE (23, 768)\n",
      "SHAPE (116, 768)\n",
      "SHAPE (27, 768)\n",
      "SHAPE (275, 768)\n",
      "SHAPE (23, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (55, 768)\n",
      "SHAPE (249, 768)\n",
      "SHAPE (186, 768)\n",
      "SHAPE (62, 768)\n",
      "SHAPE (38, 768)\n",
      "SHAPE (62, 768)\n",
      "SHAPE (29, 768)\n",
      "SHAPE (438, 768)\n",
      "SHAPE (99, 768)\n",
      "SHAPE (703, 768)\n",
      "SHAPE (377, 768)\n",
      "SHAPE (34, 768)\n",
      "SHAPE (225, 768)\n",
      "SHAPE (320, 768)\n",
      "SHAPE (205, 768)\n",
      "SHAPE (28, 768)\n",
      "SHAPE (227, 768)\n",
      "SHAPE (96, 768)\n",
      "SHAPE (444, 768)\n",
      "SHAPE (946, 768)\n",
      "SHAPE (381, 768)\n",
      "SHAPE (539, 768)\n",
      "SHAPE (334, 768)\n",
      "Done in : 271.19542694091797\n"
     ]
    }
   ],
   "source": [
    "start  = time.time()\n",
    "vec = clean_text[:100].apply(lambda x: get_features(x, tokenizer))\n",
    "print(\"Done in :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = pd.DataFrame(list(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf  = pd.concat([pd.DataFrame(vec[0]), pd.DataFrame(vec[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.17495823, -0.047251303, 0.08547299, -0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.29663602, -0.048084375, -0.19339488, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [[-0.17495823, -0.047251303, 0.08547299, -0.23...\n",
       "1  [[-0.29663602, -0.048084375, -0.19339488, -0.1..."
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf = pd.DataFrame(vec.values)\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.30300143,\n",
       " 0.022768296,\n",
       " -0.2102704,\n",
       " -0.27946776,\n",
       " 0.003865334,\n",
       " 0.00037628558,\n",
       " 0.12623006,\n",
       " 0.2451834,\n",
       " -0.23199065,\n",
       " -0.37141207,\n",
       " -0.14055876,\n",
       " -0.07224036,\n",
       " 0.11907644,\n",
       " 0.26206806,\n",
       " -0.02275215,\n",
       " 0.3110061,\n",
       " -0.08479783,\n",
       " 0.0017293976,\n",
       " 0.1917347,\n",
       " -0.032649785,\n",
       " -0.22506677,\n",
       " -0.35503232,\n",
       " -0.12787299,\n",
       " -0.12504528,\n",
       " -0.11132049,\n",
       " -0.21208,\n",
       " -0.19066194,\n",
       " 0.110723935,\n",
       " 0.12674204,\n",
       " -0.01680362,\n",
       " -0.06544068,\n",
       " 0.2234552,\n",
       " -0.2211286,\n",
       " -0.23936544,\n",
       " 0.10907316,\n",
       " 0.0993568,\n",
       " -0.07285218,\n",
       " -0.114121474,\n",
       " -0.12802336,\n",
       " -0.10470481,\n",
       " -0.22364822,\n",
       " 0.03407946,\n",
       " 0.07495353,\n",
       " 0.17245778,\n",
       " -0.10355012,\n",
       " -0.07774525,\n",
       " -2.1201088,\n",
       " 0.046292488,\n",
       " -0.33589262,\n",
       " 0.054205175,\n",
       " 0.24057956,\n",
       " -0.049570806,\n",
       " 0.23928027,\n",
       " 0.26276356,\n",
       " 0.25116017,\n",
       " 0.2676981,\n",
       " -0.22528663,\n",
       " 0.3404603,\n",
       " -0.042630654,\n",
       " 0.005517002,\n",
       " 0.35145485,\n",
       " 0.051978648,\n",
       " -0.13102157,\n",
       " -0.2091414,\n",
       " 0.32465097,\n",
       " 0.0151490355,\n",
       " 0.0490305,\n",
       " 0.09835112,\n",
       " -0.30338332,\n",
       " 0.3270958,\n",
       " -0.322596,\n",
       " -0.064438276,\n",
       " 0.23291215,\n",
       " 0.23402478,\n",
       " 0.16304952,\n",
       " -0.005422691,\n",
       " 0.084445424,\n",
       " -0.089272894,\n",
       " -0.23803647,\n",
       " 0.036830097,\n",
       " -0.07733655,\n",
       " 0.18462154,\n",
       " 0.09410833,\n",
       " 0.21051751,\n",
       " -0.18520582,\n",
       " 0.2844189,\n",
       " -0.46818414,\n",
       " 0.053255364,\n",
       " 0.01942283,\n",
       " 0.42918158,\n",
       " 0.009417579,\n",
       " -0.0630023,\n",
       " 0.08793327,\n",
       " 0.004894338,\n",
       " 0.26978293,\n",
       " -0.28595358,\n",
       " 0.1305627,\n",
       " 0.12442361,\n",
       " 0.09686189,\n",
       " 0.05407782,\n",
       " -0.035652358,\n",
       " -0.026526578,\n",
       " 0.2109346,\n",
       " -0.17423601,\n",
       " 0.43535358,\n",
       " -0.34440646,\n",
       " 0.01653574,\n",
       " -0.13198219,\n",
       " -0.2363174,\n",
       " -2.5489962,\n",
       " 0.0063923146,\n",
       " 0.19950642,\n",
       " -0.23374245,\n",
       " -0.54848814,\n",
       " -0.30323756,\n",
       " 0.34813225,\n",
       " 0.24296704,\n",
       " 0.038240623,\n",
       " 0.083725266,\n",
       " -0.16421796,\n",
       " -0.24455951,\n",
       " 0.42715168,\n",
       " 0.0133491205,\n",
       " 0.21175022,\n",
       " -0.08304482,\n",
       " 0.28325638,\n",
       " 0.15811542,\n",
       " 0.037522573,\n",
       " 0.26465458,\n",
       " 0.25379223,\n",
       " 0.03598878,\n",
       " 0.4370263,\n",
       " -0.0047829845,\n",
       " -0.04546496,\n",
       " -0.18749076,\n",
       " 0.23469774,\n",
       " 0.18917571,\n",
       " -0.006880914,\n",
       " 0.011747174,\n",
       " 0.20401141,\n",
       " -0.19793305,\n",
       " -0.2751506,\n",
       " -2.9734044,\n",
       " 0.18053962,\n",
       " 0.37038124,\n",
       " -0.12217999,\n",
       " -0.1485683,\n",
       " 0.17003646,\n",
       " 0.2335962,\n",
       " 0.1771699,\n",
       " 0.14132184,\n",
       " 0.14995728,\n",
       " -0.19396909,\n",
       " 0.19405667,\n",
       " -0.14390145,\n",
       " 0.14934888,\n",
       " 0.008253036,\n",
       " -0.050268456,\n",
       " 0.20642252,\n",
       " 0.17983012,\n",
       " 0.21545485,\n",
       " 0.01854657,\n",
       " -0.106429495,\n",
       " -0.032952223,\n",
       " -0.11438201,\n",
       " 0.15475085,\n",
       " 0.12249906,\n",
       " 0.15519255,\n",
       " 0.017032225,\n",
       " 0.016448885,\n",
       " -0.17624803,\n",
       " -0.39096117,\n",
       " 0.25713965,\n",
       " -0.12825058,\n",
       " 0.4225597,\n",
       " 0.2158291,\n",
       " -0.04086296,\n",
       " 0.29103956,\n",
       " 0.27452132,\n",
       " -0.0745247,\n",
       " 0.01810873,\n",
       " 0.6294485,\n",
       " 0.122424826,\n",
       " 0.08615144,\n",
       " 0.09526031,\n",
       " -0.03303192,\n",
       " 0.23619284,\n",
       " -0.16924252,\n",
       " 0.15219831,\n",
       " 0.12204755,\n",
       " 0.14921032,\n",
       " -0.019282807,\n",
       " 0.06080591,\n",
       " 0.04109107,\n",
       " 0.30771726,\n",
       " 0.007757954,\n",
       " 0.11070627,\n",
       " -0.37092444,\n",
       " 0.13625546,\n",
       " 0.010844303,\n",
       " -0.16815177,\n",
       " 0.03159787,\n",
       " 0.030112991,\n",
       " 0.004760415,\n",
       " -0.22984153,\n",
       " 3.547939,\n",
       " 0.22792177,\n",
       " -0.27726817,\n",
       " 0.27214068,\n",
       " 0.30625767,\n",
       " 0.2550822,\n",
       " -0.041559417,\n",
       " -0.1352294,\n",
       " -0.15393479,\n",
       " 0.51703817,\n",
       " 0.0004251073,\n",
       " -0.02339375,\n",
       " 0.16339806,\n",
       " 0.11407839,\n",
       " -0.121629134,\n",
       " 0.26479974,\n",
       " 0.1325646,\n",
       " 0.09427174,\n",
       " 0.33674163,\n",
       " -0.19912393,\n",
       " 0.651056,\n",
       " 0.24877305,\n",
       " 0.19161144,\n",
       " 0.028465051,\n",
       " -1.0269394,\n",
       " 0.27411976,\n",
       " 0.04474183,\n",
       " 0.241152,\n",
       " 0.054755278,\n",
       " -0.21003608,\n",
       " -0.21931899,\n",
       " -0.14114513,\n",
       " -0.16071339,\n",
       " 0.11197116,\n",
       " 0.036617618,\n",
       " -0.15013933,\n",
       " -0.03917485,\n",
       " 0.18631883,\n",
       " 0.05896568,\n",
       " -0.038911458,\n",
       " 0.06872776,\n",
       " 0.14540474,\n",
       " 0.20389028,\n",
       " -0.025185345,\n",
       " -0.058837567,\n",
       " 0.20688991,\n",
       " -0.28100806,\n",
       " -0.031369142,\n",
       " -0.1659812,\n",
       " -0.15006304,\n",
       " 0.0681217,\n",
       " 0.28029743,\n",
       " 0.08343593,\n",
       " -0.20290709,\n",
       " 0.09210472,\n",
       " -0.089773715,\n",
       " 0.12575842,\n",
       " 0.2972868,\n",
       " -0.051901236,\n",
       " -0.33485544,\n",
       " -0.4262396,\n",
       " -0.117272004,\n",
       " -0.30861005,\n",
       " 0.016148098,\n",
       " -0.064406626,\n",
       " 0.17723398,\n",
       " 0.09888962,\n",
       " -0.31231728,\n",
       " -4.1488442,\n",
       " -0.13184509,\n",
       " -0.30140597,\n",
       " 0.22908427,\n",
       " 0.3518838,\n",
       " -0.34833938,\n",
       " 0.19375303,\n",
       " 0.19569671,\n",
       " 0.12634936,\n",
       " -0.06834424,\n",
       " 0.57354623,\n",
       " 0.012819463,\n",
       " 0.052439895,\n",
       " 0.066192016,\n",
       " -0.2964722,\n",
       " 0.09634732,\n",
       " -0.11433046,\n",
       " -0.30051145,\n",
       " 0.33698836,\n",
       " -0.110585034,\n",
       " 0.07615229,\n",
       " 0.03077784,\n",
       " -0.060814742,\n",
       " 0.090706624,\n",
       " 0.07362387,\n",
       " -0.19933671,\n",
       " -0.38887087,\n",
       " -0.17852253,\n",
       " -0.048631024,\n",
       " -0.003910277,\n",
       " -0.014326636,\n",
       " -0.28931233,\n",
       " 0.019958278,\n",
       " 0.014507895,\n",
       " -0.26961717,\n",
       " -2.3163195,\n",
       " -0.2858802,\n",
       " -0.00026897603,\n",
       " -0.37580305,\n",
       " 0.13322955,\n",
       " 0.000116813695,\n",
       " 0.36485395,\n",
       " -0.07094116,\n",
       " -0.22075668,\n",
       " 0.059597827,\n",
       " -0.004804116,\n",
       " -0.029113673,\n",
       " 0.07930588,\n",
       " 0.115012586,\n",
       " 0.34192052,\n",
       " -0.12635228,\n",
       " 0.07759235,\n",
       " -0.013385071,\n",
       " 0.050483003,\n",
       " -0.03212438,\n",
       " 0.11193268,\n",
       " -0.12968019,\n",
       " -0.315532,\n",
       " 0.045186497,\n",
       " -0.24891964,\n",
       " 0.38251486,\n",
       " -0.3567763,\n",
       " 0.17640713,\n",
       " -0.342727,\n",
       " -0.24065742,\n",
       " 0.22235923,\n",
       " -0.21451822,\n",
       " -0.041204337,\n",
       " 0.12990826,\n",
       " -0.19670646,\n",
       " -0.12235349,\n",
       " -0.1542972,\n",
       " 0.3986362,\n",
       " 0.5186442,\n",
       " 0.055830438,\n",
       " -0.1775946,\n",
       " 0.53721035,\n",
       " 0.048151337,\n",
       " 0.048737325,\n",
       " 0.12930219,\n",
       " 0.20139338,\n",
       " 0.35099444,\n",
       " -0.03177901,\n",
       " -0.051548824,\n",
       " 0.29894406,\n",
       " 0.05579177,\n",
       " -0.19009474,\n",
       " 1.0074059,\n",
       " -0.11577737,\n",
       " 0.14572085,\n",
       " -0.23125206,\n",
       " 0.3997143,\n",
       " -0.00785846,\n",
       " -0.21421483,\n",
       " 0.3919081,\n",
       " 0.2716648,\n",
       " -5.0109917e-05,\n",
       " 0.0018005369,\n",
       " -0.18546923,\n",
       " -0.088210136,\n",
       " -0.1352104,\n",
       " -0.015550412,\n",
       " -0.36163178,\n",
       " 0.086103186,\n",
       " -0.17675738,\n",
       " 0.029578269,\n",
       " 0.20387742,\n",
       " -0.16825022,\n",
       " -0.7470919,\n",
       " -0.09953611,\n",
       " -0.14022602,\n",
       " 0.0810286,\n",
       " 0.070128046,\n",
       " -0.020534229,\n",
       " -0.12013645,\n",
       " -0.30870682,\n",
       " 0.07883646,\n",
       " 0.03238206,\n",
       " 0.044847403,\n",
       " 0.035299513,\n",
       " 0.19744618,\n",
       " -0.11062659,\n",
       " 0.039051734,\n",
       " -0.51495355,\n",
       " 0.22473568,\n",
       " -0.07337256,\n",
       " 0.21354523,\n",
       " 0.27454764,\n",
       " 0.18942516,\n",
       " 0.04590786,\n",
       " 0.0663758,\n",
       " 0.24483894,\n",
       " -0.48612934,\n",
       " 0.30289277,\n",
       " -0.013564402,\n",
       " 0.11601837,\n",
       " -0.42834568,\n",
       " -0.07974053,\n",
       " -0.18106876,\n",
       " -0.24008745,\n",
       " -0.13851008,\n",
       " -0.31004313,\n",
       " 0.015103162,\n",
       " 0.09652074,\n",
       " -0.035203364,\n",
       " -0.04719209,\n",
       " 0.16877139,\n",
       " 0.43426225,\n",
       " 0.29243782,\n",
       " 0.7777466,\n",
       " 0.17633905,\n",
       " -0.28842002,\n",
       " 0.1551205,\n",
       " 0.101169296,\n",
       " 0.23217098,\n",
       " 0.17931454,\n",
       " 0.13638419,\n",
       " -0.034097787,\n",
       " -0.026741013,\n",
       " 0.14269418,\n",
       " -0.088852175,\n",
       " 0.029924566,\n",
       " -0.101058446,\n",
       " -0.31457812,\n",
       " 0.19552827,\n",
       " -0.03594037,\n",
       " 0.20882183,\n",
       " 0.008016447,\n",
       " -0.43589026,\n",
       " -0.045602947,\n",
       " -0.2650817,\n",
       " -0.22757548,\n",
       " 0.36747888,\n",
       " 0.24406017,\n",
       " 0.24107677,\n",
       " 0.29157475,\n",
       " -0.0610211,\n",
       " -0.0630146,\n",
       " 0.24872655,\n",
       " -0.04445045,\n",
       " 0.22865823,\n",
       " -0.111812346,\n",
       " 0.06678659,\n",
       " -0.0414723,\n",
       " 0.36164278,\n",
       " 0.07482288,\n",
       " -0.1786684,\n",
       " -0.17146035,\n",
       " -0.054238442,\n",
       " 0.075109735,\n",
       " -0.014646819,\n",
       " 0.082210794,\n",
       " -0.21085009,\n",
       " 0.0013845568,\n",
       " -0.1864401,\n",
       " -0.13430709,\n",
       " 0.0936729,\n",
       " -1.1899045,\n",
       " 0.18353724,\n",
       " -0.0316988,\n",
       " -0.09533165,\n",
       " 0.0072532133,\n",
       " -0.023651898,\n",
       " 0.12728487,\n",
       " 0.24533896,\n",
       " 0.08121132,\n",
       " -0.18763499,\n",
       " 0.02235793,\n",
       " -0.21707036,\n",
       " -0.0059153233,\n",
       " 0.004789374,\n",
       " -0.08709703,\n",
       " 0.056732435,\n",
       " 0.02657265,\n",
       " 0.19671756,\n",
       " 0.18629092,\n",
       " 0.055848736,\n",
       " 0.032819625,\n",
       " 0.3659631,\n",
       " 0.057359703,\n",
       " -0.036896344,\n",
       " -0.095141254,\n",
       " -0.21942852,\n",
       " -0.21643789,\n",
       " 0.35027674,\n",
       " 0.15981391,\n",
       " 0.15045427,\n",
       " 0.070663676,\n",
       " -0.3457839,\n",
       " -0.36650255,\n",
       " 0.11674229,\n",
       " -0.01939707,\n",
       " 0.07468106,\n",
       " 0.22801217,\n",
       " -0.049196783,\n",
       " 0.13704096,\n",
       " 0.047944024,\n",
       " -0.024380846,\n",
       " 0.07498585,\n",
       " 0.11509962,\n",
       " -0.1624212,\n",
       " 0.34812143,\n",
       " 0.15723595,\n",
       " -0.41399163,\n",
       " 0.051027503,\n",
       " 0.060162406,\n",
       " 0.009342589,\n",
       " -0.076461345,\n",
       " -0.0022771559,\n",
       " -0.13321517,\n",
       " 0.060915228,\n",
       " 0.013634426,\n",
       " -0.019410484,\n",
       " -0.18013151,\n",
       " 0.16502166,\n",
       " 0.1227308,\n",
       " 0.14253958,\n",
       " 0.3064202,\n",
       " -0.34657234,\n",
       " 0.05168947,\n",
       " 0.1368877,\n",
       " -0.10325737,\n",
       " -0.5829113,\n",
       " -0.012686117,\n",
       " 0.06378206,\n",
       " -0.30250058,\n",
       " 0.031658173,\n",
       " -0.10363741,\n",
       " -0.030332316,\n",
       " 0.13068336,\n",
       " 0.022422876,\n",
       " -0.38127148,\n",
       " 0.17924301,\n",
       " 0.04388345,\n",
       " -0.09738724,\n",
       " 0.077250265,\n",
       " -0.03243034,\n",
       " -0.20583653,\n",
       " -0.23554683,\n",
       " -0.09012164,\n",
       " 0.25614274,\n",
       " 0.1349685,\n",
       " -0.12226303,\n",
       " -0.012155074,\n",
       " 0.23618373,\n",
       " 0.08792587,\n",
       " -0.10719674,\n",
       " -0.20668606,\n",
       " -0.40239352,\n",
       " 0.41964072,\n",
       " 0.17760818,\n",
       " -0.017965103,\n",
       " -0.04226772,\n",
       " 0.0147918835,\n",
       " 0.105793424,\n",
       " -0.15175866,\n",
       " 0.10996746,\n",
       " 0.077578776,\n",
       " 0.17762828,\n",
       " 0.1897135,\n",
       " 0.034063615,\n",
       " 0.016549207,\n",
       " 0.17222907,\n",
       " 0.14337929,\n",
       " 0.06381999,\n",
       " -0.12909523,\n",
       " -0.012982468,\n",
       " 0.0205903,\n",
       " 0.045295175,\n",
       " -0.06521883,\n",
       " 0.035238888,\n",
       " 0.1764526,\n",
       " -0.32321152,\n",
       " -0.17760561,\n",
       " 0.07797851,\n",
       " 2.0196826,\n",
       " 0.21562023,\n",
       " 0.010043005,\n",
       " -0.013324454,\n",
       " 0.29810876,\n",
       " 0.010244955,\n",
       " -0.01933394,\n",
       " 0.03281209,\n",
       " -0.27140203,\n",
       " 0.20461813,\n",
       " 0.24293193,\n",
       " -0.00994813,\n",
       " -0.4071767,\n",
       " 0.013664279,\n",
       " 0.29573086,\n",
       " 0.12098252,\n",
       " -0.23143576,\n",
       " 0.0985978,\n",
       " -0.17826502,\n",
       " -0.11233915,\n",
       " -0.4336663,\n",
       " 0.5413413,\n",
       " 0.0012677513,\n",
       " -0.101080604,\n",
       " 0.15201022,\n",
       " 0.1297068,\n",
       " 0.07890441,\n",
       " -0.042484485,\n",
       " 0.011633909,\n",
       " -0.04681663,\n",
       " -0.03429847,\n",
       " -0.047006365,\n",
       " 0.057020817,\n",
       " 0.36969694,\n",
       " -0.2193734,\n",
       " 0.13538212,\n",
       " 0.025845464,\n",
       " -0.16255727,\n",
       " -0.07698404,\n",
       " 0.0784092,\n",
       " 0.051040407,\n",
       " -0.10536241,\n",
       " 0.49048844,\n",
       " -0.049613677,\n",
       " 0.08439625,\n",
       " 0.44153595,\n",
       " -0.022257734,\n",
       " -0.15942156,\n",
       " 0.06333098,\n",
       " 0.49313185,\n",
       " 0.23692557,\n",
       " 0.024626048,\n",
       " -0.15780777,\n",
       " 0.24764998,\n",
       " 0.052019745,\n",
       " 0.054805983,\n",
       " 0.0696468,\n",
       " 0.01347182,\n",
       " -0.0865822,\n",
       " 0.23254827,\n",
       " -0.1118121,\n",
       " 0.3842251,\n",
       " 0.17747803,\n",
       " 0.1694971,\n",
       " 0.104639165,\n",
       " 0.16504964,\n",
       " -0.2736558,\n",
       " 0.23507702,\n",
       " 0.21993376,\n",
       " -0.16209705,\n",
       " 0.017524583,\n",
       " -0.08678745,\n",
       " 0.35535863,\n",
       " 0.19754004,\n",
       " 0.035517026,\n",
       " 0.098127045,\n",
       " 0.45334014,\n",
       " 0.0028419062,\n",
       " -0.044032786,\n",
       " -2.925159,\n",
       " -0.26262382,\n",
       " -0.016980113,\n",
       " 0.0446999,\n",
       " 0.07504108,\n",
       " 0.5599565,\n",
       " 0.16764396,\n",
       " -0.13566163,\n",
       " -0.16267885,\n",
       " -0.039031737,\n",
       " 0.20773631,\n",
       " -0.11124523,\n",
       " 0.1284569,\n",
       " -0.057108402,\n",
       " 0.2437845,\n",
       " 0.007970004,\n",
       " 0.072216414,\n",
       " -0.27859837,\n",
       " 0.018357262,\n",
       " 0.00580608,\n",
       " -0.19314702,\n",
       " 0.054013725,\n",
       " -0.21195883,\n",
       " -0.27691665,\n",
       " -0.502694,\n",
       " 0.11513242,\n",
       " -0.11094761,\n",
       " -0.306101,\n",
       " 0.06556054,\n",
       " 0.3599761,\n",
       " 0.059509248,\n",
       " 0.28753945,\n",
       " 0.022061579,\n",
       " 0.40854916,\n",
       " -0.016432527,\n",
       " -0.33836803,\n",
       " -0.022167102,\n",
       " 0.12862727,\n",
       " -0.23163044,\n",
       " 0.21862616,\n",
       " -0.51740056,\n",
       " 0.10501865,\n",
       " -0.030503742,\n",
       " -0.1487927,\n",
       " -0.21559729,\n",
       " 0.005997808,\n",
       " 0.3578943,\n",
       " -0.12482069,\n",
       " 0.54577,\n",
       " -0.19832394,\n",
       " -0.16980241,\n",
       " 0.09335203,\n",
       " 0.21236321,\n",
       " -0.048269138,\n",
       " 0.320652,\n",
       " 0.1358388,\n",
       " 0.062839635,\n",
       " 0.07687571,\n",
       " -0.20256235,\n",
       " -0.36721775,\n",
       " 0.19990103,\n",
       " 0.18853396,\n",
       " -0.056393173,\n",
       " -0.0006691033,\n",
       " 0.13002881,\n",
       " -0.31946075,\n",
       " -0.24994087,\n",
       " 0.19019851,\n",
       " 0.11431419,\n",
       " 0.151127,\n",
       " -0.2073815,\n",
       " -0.26139876,\n",
       " 0.40702575,\n",
       " -0.045029778,\n",
       " 0.064868286,\n",
       " 0.12598017,\n",
       " 0.25547126,\n",
       " 0.2988351,\n",
       " 0.21854605,\n",
       " 0.12640874,\n",
       " -0.08322976,\n",
       " -0.3948885,\n",
       " -0.15240066,\n",
       " -0.06508082,\n",
       " 0.20992215,\n",
       " -7.9560313,\n",
       " -0.25401905,\n",
       " -0.2811319,\n",
       " -0.22203453,\n",
       " 0.0028127579,\n",
       " -0.27308017,\n",
       " 0.08078887,\n",
       " -0.11936646,\n",
       " 0.15050338,\n",
       " -0.04510103,\n",
       " 0.1167148,\n",
       " -0.07674426,\n",
       " -0.34849247,\n",
       " -0.2573829,\n",
       " -0.016273687,\n",
       " 0.486855,\n",
       " -0.19025691,\n",
       " -0.070610255,\n",
       " 0.01692615,\n",
       " -0.20878595,\n",
       " 0.028940566,\n",
       " -0.19982912,\n",
       " 0.23227198,\n",
       " 0.30046746,\n",
       " -0.24047399,\n",
       " -0.21334276,\n",
       " -0.0005003872,\n",
       " -0.03700559,\n",
       " -0.24112153,\n",
       " 0.29538456,\n",
       " -0.02458401,\n",
       " 0.16176927,\n",
       " -0.11660884,\n",
       " 0.19266301,\n",
       " 0.11930979,\n",
       " -0.13008893,\n",
       " -0.07221339,\n",
       " -0.17507303,\n",
       " -0.019006584,\n",
       " -0.15741238,\n",
       " -0.09503776,\n",
       " -0.09240607,\n",
       " -0.051398896,\n",
       " -0.005136792,\n",
       " -0.064351015,\n",
       " 0.068149164,\n",
       " 0.11886535,\n",
       " 0.15919639,\n",
       " -0.038884334,\n",
       " -0.10818405,\n",
       " -0.10785867,\n",
       " -0.0197668,\n",
       " 0.05250032,\n",
       " -0.15664198,\n",
       " 0.01843645,\n",
       " 0.039722625,\n",
       " -0.029166155,\n",
       " -0.122270346,\n",
       " 0.15867338,\n",
       " -0.036817312,\n",
       " -0.07977596,\n",
       " -0.21697639,\n",
       " -2.0385907,\n",
       " -0.03422095,\n",
       " -0.060803365,\n",
       " -0.12841508,\n",
       " 0.13830747,\n",
       " -0.06242192,\n",
       " 0.18459146,\n",
       " 0.22175583,\n",
       " 0.25721252,\n",
       " 0.26328206,\n",
       " -0.14442664,\n",
       " 0.2732651,\n",
       " 0.14181441,\n",
       " -0.10164377,\n",
       " 0.19779341,\n",
       " -0.133745,\n",
       " -0.03268885,\n",
       " 0.059485886,\n",
       " -0.17596452,\n",
       " 0.20561141,\n",
       " -0.004682432,\n",
       " 0.09539855,\n",
       " -0.18104959,\n",
       " 0.3252844,\n",
       " -0.16126809,\n",
       " -0.09160078,\n",
       " 0.18558867,\n",
       " -0.022451833,\n",
       " 0.003325709,\n",
       " -0.11144407,\n",
       " 0.074652895,\n",
       " 0.11064566,\n",
       " -0.05131235,\n",
       " -0.06141781,\n",
       " 0.07156533,\n",
       " 0.23146586,\n",
       " 0.27407667,\n",
       " 0.10596385,\n",
       " -0.079361856,\n",
       " 0.03649881,\n",
       " -0.1506683,\n",
       " -0.072171584,\n",
       " 0.10005977,\n",
       " 0.21937366,\n",
       " 0.0023893877,\n",
       " -0.01155766,\n",
       " 0.20334543,\n",
       " 0.19140594,\n",
       " 0.11686414,\n",
       " -0.27406055,\n",
       " 0.056734122,\n",
       " -0.06704341,\n",
       " 0.34012234,\n",
       " 0.25752822,\n",
       " -0.040982455,\n",
       " 0.080572754,\n",
       " 0.08868426,\n",
       " -0.23083739,\n",
       " 0.042441968,\n",
       " -0.13620572,\n",
       " 0.038360395,\n",
       " -0.116806224,\n",
       " 0.058680452,\n",
       " -2.5153484,\n",
       " 0.2831127,\n",
       " 0.13396153,\n",
       " -0.13562906,\n",
       " -0.31958082,\n",
       " 0.020775262,\n",
       " 0.38610926,\n",
       " 0.21346058,\n",
       " 0.04314535,\n",
       " -0.08169102,\n",
       " -0.19874495,\n",
       " -0.026106963,\n",
       " 0.3733043,\n",
       " 0.12634437,\n",
       " -0.070689715,\n",
       " 0.035040017,\n",
       " 0.163497,\n",
       " 0.0002867328,\n",
       " -0.10067236,\n",
       " 0.042551752,\n",
       " 0.21872236,\n",
       " 0.22741622,\n",
       " 0.32230288,\n",
       " -0.077491164,\n",
       " -0.09836344,\n",
       " -0.01436034,\n",
       " 0.07398915,\n",
       " 0.2950299,\n",
       " -0.023979418,\n",
       " -0.056355335,\n",
       " -0.031012774,\n",
       " -0.21586147,\n",
       " -0.11592841,\n",
       " -2.7828107,\n",
       " 0.26362196,\n",
       " 0.35164008,\n",
       " -0.14856076,\n",
       " -0.012020674,\n",
       " 0.05611835,\n",
       " 0.06354889,\n",
       " 0.123754404,\n",
       " 0.1024651,\n",
       " 0.12686865,\n",
       " -0.06825727,\n",
       " -0.003696732,\n",
       " -0.16109875,\n",
       " -0.06848925,\n",
       " -0.034747683,\n",
       " 0.061065234,\n",
       " 0.16663682,\n",
       " 0.27416435,\n",
       " -0.0009822533,\n",
       " -0.028957317,\n",
       " -0.03678758,\n",
       " -0.19979027,\n",
       " -0.14181934,\n",
       " -0.040498365,\n",
       " 0.13949436,\n",
       " 0.15146372,\n",
       " 0.14058484,\n",
       " 0.044299684,\n",
       " -0.14452578,\n",
       " 0.03889536,\n",
       " 0.16227686,\n",
       " -0.038480736,\n",
       " 0.25628987,\n",
       " 0.072255895,\n",
       " 0.08519414,\n",
       " 0.19040644,\n",
       " -0.102049105,\n",
       " 0.04421886,\n",
       " -0.054093007,\n",
       " 0.23582974,\n",
       " -0.06487055,\n",
       " 0.25138107,\n",
       " -0.030310802,\n",
       " -0.15558015,\n",
       " 0.045936376,\n",
       " -0.19489826,\n",
       " 0.14706062,\n",
       " 0.19602159,\n",
       " -0.16739263,\n",
       " -0.19102186,\n",
       " 0.12405263,\n",
       " 0.115295075,\n",
       " 0.08235996,\n",
       " -0.04422633,\n",
       " -0.008751812,\n",
       " -0.36736202,\n",
       " 0.28921697,\n",
       " -0.055014998,\n",
       " -0.15356424,\n",
       " -0.090561196,\n",
       " -0.15545152,\n",
       " 0.14475419,\n",
       " -0.09450063,\n",
       " 3.5879824,\n",
       " 0.017681453,\n",
       " -0.07937687,\n",
       " -0.004561297,\n",
       " 0.10430845,\n",
       " -0.011766846,\n",
       " -0.03415058,\n",
       " -0.05621032,\n",
       " -0.06614887,\n",
       " 0.18952812,\n",
       " -0.04809222,\n",
       " 0.13186318,\n",
       " -0.028150277,\n",
       " -0.08858985,\n",
       " 0.066408515,\n",
       " 0.095730804,\n",
       " 0.18435018,\n",
       " -0.0648991,\n",
       " 0.19018698,\n",
       " -0.25408527,\n",
       " 0.24329716,\n",
       " 0.17659053,\n",
       " -0.10961688,\n",
       " 0.024610369,\n",
       " -1.0471281,\n",
       " 0.02204818,\n",
       " -0.11784172,\n",
       " ...]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pca.fit_transform(vec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 73)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 768 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 768 samples in 0.120s...\n",
      "[t-SNE] Computed conditional probabilities for sample 768 / 768\n",
      "[t-SNE] Mean sigma: 0.397150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-369-a33c7e8ad8f0>\", line 2, in <module>\n",
      "    tsne_results = tsne.fit_transform(vec.T)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1108, in fit_transform\n",
      "    embedding = self._fit(X)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1004, in _fit\n",
      "    return self._tsne(\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1056, in _tsne\n",
      "    params, kl_divergence, it = _gradient_descent(obj_func, params, **opt_args)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 398, in _gradient_descent\n",
      "    error, grad = objective(p, *args, **kwargs)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 279, in _kl_divergence_bh\n",
      "    error = _barnes_hut_tsne.gradient(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1465, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-369-a33c7e8ad8f0>\", line 2, in <module>\n",
      "    tsne_results = tsne.fit_transform(vec.T)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1108, in fit_transform\n",
      "    embedding = self._fit(X)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1004, in _fit\n",
      "    return self._tsne(\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 1056, in _tsne\n",
      "    params, kl_divergence, it = _gradient_descent(obj_func, params, **opt_args)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 398, in _gradient_descent\n",
      "    error, grad = objective(p, *args, **kwargs)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\", line 279, in _kl_divergence_bh\n",
      "    error = _barnes_hut_tsne.gradient(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ragou/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=250)\n",
    "tsne_results = tsne.fit_transform(vec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=tsne_results[:,1], y=tsne_results[:,0],\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6AAAAI/CAYAAABpgrSTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmkUlEQVR4nO3dfYxd6UHf8d/jefPM2N7MZL043dllIzV1hFLatFYKjdRKBKQUEKiVKkEFEqXStlJpQ4WEmuav/leJCoEEarsKtJWIQAiIqCgUggBVSE3K5qU0yWZRmjZZh2zWiyesPeOdGTtP/7DHsZ15v+c+95w7n4+0ys7x+Mxj36vsfOd5OaXWGgAAABi3M5MeAAAAAKeDAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACamJ3EF3388cfrM888M4kvDQAAwJh99KMffbXWevHR6xMJ0GeeeSbPP//8JL40AAAAY1ZK+fxe1y3BBQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATcxOegAAAAAcrtaa9c2dbGzdzvLCbFaW5lJKmfSwjkWAAgAA9FytNS++fCNX12/dv7a2spjLl84PKkItwQUAAOi59c2dh+IzSa6u38r65s6ERnQyAhQAAKDnNrZuH+t6XwlQAACAnlte2Hv35H7X+0qAAgAA9NzK0lzWVhYfura2spiVpbkJjehkhpXLAAAAp1ApJZcvnc8TF846BRcAAIDxKqVkdXk+q8vzkx7KiVmCCwAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACa6CxASykzpZSPl1J+o6t7AgAAMD26nAF9T5IXOrwfAAAAU6STAC2lrCX5riTv7+J+AAAATJ+uZkB/KsmPJ/lqR/cDAABgyowcoKWU707ySq31o4d83rOllOdLKc9fu3Zt1C8LAADAwHQxA/rOJN9TSvl/SX4pybeVUn7h0U+qtT5Xa71Sa71y8eLFDr4sAAAAQzJygNZa31trXau1PpPk+5L8Xq31B0YeGQAAAFPFc0ABAABoYrbLm9Va/yDJH3R5TwAAAKaDGVAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhi5AAtpZwtpfzPUsr/KqV8qpTyr7sYGAAAANNltoN7bCX5tlrrzVLKXJI/LKX8Vq31wx3cGwAAgCkxcoDWWmuSm/c+nLv3Tx31vgAAAEyXTvaAllJmSimfSPJKkg/VWj/SxX0BAACYHp0EaK31Tq31ryZZS/KOUsrbHv2cUsqzpZTnSynPX7t2rYsvCwAAwIB0egpurfUrSX4/ybv3+LXnaq1Xaq1XLl682OWXBQAAYAC6OAX3YinlDff+fTHJdyT5zKj3BQAAYLp0cQrum5L851LKTO4G7S/XWn+jg/sCAAAwRbo4BfePk7y9g7EAAAAwxTrdAwoAAAD7EaAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQxcoCWUp4qpfx+KeXTpZRPlVLe08XAAAAAmC6zHdzjdpIfq7V+rJRyPslHSykfqrV+uoN7AwAAMCVGngGttX6p1vqxe/9+I8kLSZ4c9b4AAABMl073gJZSnkny9iQf6fK+AAAADF9nAVpKOZfkV5P8aK31tT1+/dlSyvOllOevXbvW1ZcFAABgIDoJ0FLKXO7G5wdqrb+21+fUWp+rtV6ptV65ePFiF18WAACAAeniFNyS5OeSvFBr/cnRhwQAAMA06mIG9J1JfjDJt5VSPnHvn+/s4L4AAABMkZEfw1Jr/cMkpYOxAAAAMMU6PQUXAAAA9iNAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQxOykBwDTptaa9c2dbGzdzvLCbFaW5lJKmfSwAABg4gQodKjWmhdfvpGr67fuX1tbWczlS+dFKAAAp54luNCh9c2dh+IzSa6u38r65s6ERgQAAP0hQKFDG1u3j3UdAABOEwEKHVpe2HtV+37XAQDgNBGg0KGVpbmsrSw+dG1tZTErS3MTGhEAAPSHaRnoUCklly+dzxMXzjoFFwAAHiFAoWOllKwuz2d1eX7SQwEAgF6xBBcAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABowim49F6tNeubOx5rAgAAAydA6bVaa158+Uaurt+6f21tZTGXL50XoQAAMDCW4NJr65s7D8Vnklxdv5X1zZ0JjQgAADgpAUqvbWzdPtZ1AACgvwQovba8sPcq8f2uAwAA/SVA6bWVpbmsrSw+dG1tZTErS3MTGhEAAHBSppHotVJKLl86nycunHUKLgAADJwApfdKKVldns/q8vykhwIAAIzAElwAAACaEKAAAAA00UmAllJ+vpTySinlk13cDwAAgOnT1Qzof0ry7o7uBQAAwBTqJEBrrf89yfUu7gUAAMB0sgcUAACAJpoFaCnl2VLK86WU569du9bqywIAANATzQK01vpcrfVKrfXKxYsXW31ZAAAAesISXAAAAJro6jEsv5jkfyS5XEq5Wkr5R13cFwAAgOkx28VNaq3f38V9AAAAmF6W4AIAANBEJzOgnD611qxv7mRj63aWF2azsjSXUsqkhwUAAPSYAOXYaq158eUbubp+6/61tZXFXL50XoQCAAD7sgSXY1vf3HkoPpPk6vqtrG/uTGhEAADAEAhQjm1j6/axrgMAACQClBNYXth75fZ+1wEAABIBygmsLM1lbWXxoWtrK4tZWZqb0IgAAIAhMGXFsZVScvnS+Txx4exDp+AmyfWNbSfjAgAAexKgnEgpJavL81ldnk/iZFwAAOBwluDSCSfjAgAAhxGgdKLPJ+PWWnN9YzsvXd/M9Y3t1FonPSQAADiVLMGlE309GdfSYAAA6A8zoD0z1Nm6vp6Ma2kwAAD0hxnQHhnybN1+J+NOetwHLQ3ePUAJAABoQ4D2yH6zdU9cODuIWHr0ZNw+6OvSYAAAOI0swe2RPh/kM1R9XRoMAACnkWmgHjFb172+Lg0GAIDTSNn0yO5s3aN7QA+brau1Zn1zR2Dto49LgwEA4DQSoD1yktm6IR9cBAAAnC4CtGeOO1s39IOLAACA08MhRAPn4CIAAGAozIAO3HEPLrJfFAAAmBQBOnDHObjIflEAAGCSBOjA7DWD+dDBRfMzqbm7D/TRGU77RQEAgEkSoANy0Azm6vJ8VpbmDpzhPGi/qAAFAADGzSFEA7LfDOb65s6Rfv24+0UBAAC6JEAHZGPrdmpqbmzdzqs3t3Lj3se7M5uHnYi7u1/0QfvtFwUAAOiaqa8BWZ6fyZ+u38q1m9v3r108N5+//vTK3V8/ZIazlPLwflGn4AIAAA2ZAR2QmmRpfja7uVjufVzvfXyUGc5SSlaX5/PU6lJWl+fFJwAA0IwZ0Ak67jM5N7fvZHV5LhcWH8vW7TtZmJ3J7Jm7198YM5wAAEC/CdAJOckzOZcXZlNTMnPm7sxncndW9MGlt7sznE61BQAA+sYS3Ak57MTavbQ8RKjWmusb23np+maub2yn1nr4bwIAADiAGdAJOckzOVstsT3J7OwkHHcJMwAAMFkCtIG9Qumkz+RsscR2v9nZJy6c7c3S3qFEMgAA8DUCdMz2C6W/9A3nsray+HXX+/BMzt3njd7cupOtnTtZmJvJuYWZA2dnWxtCJAMAAA8ToGO2Vyi9tL6ZxfmZLM/P5C3fcC6lJOcW5o60hLTFstPDnjfaBydZwgwAAEyWAB2zR0OppuaL67dya/vO/ZNs11YW89TK0pHis8Wy0689b3Q7NV//vNE+OOkSZgAAYHJ8tz5mjwbRza07+bOb23nTY187zfaoS0dbLTs97Hmj43aUWd7dE4H7uIQZAADYmwAds0dDaXvnTp5eXcrsmTw0o3iUpaOtlp0e5Xmj43LUWd5WJwIDAADdEaBj8uAs3sXzC3ni/EI2tu/kq/VcPvvlG6l5OJSOEnetlp1OcnbxOLO8LU4EBgAAuiNAx+CgWbwkubV950Rx1yoMR51dHOWgJIcLAQDA9BKgI9ortg6bxTso7g6Kt5bLTk86uzjqQUkOFwIAgOnlu/oR7Bdby/Mze37+7izefnF3lHjr+7LTUQ9KcrgQAABMLwE6gv1i6y3fcG7Pzz9sFu8o8dbiOaCjGHUJrcOFAABgegnQRxwn8PaLrVJyolm8w+Kt1XNAR9HFEtq+z/ICAAAnI0AfcNzA2y+qzi3M5amVpWPP4h0Wb6Msb201c2oJLQAAsB8B+oDjBt5BsXWSWbzD4u2ky1tbzpxaQgsAAOxHgD7guIHXdWwddr+TLm8d9WCg47KEFgAA2IsAfcBJAq/r2Drofidd3jpNz9bs+yFM3OV1AgBgLwL0AX3fv3jSGddpebbmEA5hwusEAMD+hlUgY9bVktpxzv6MY2/pULReSszJeJ0AANiPAH3EqEtq+zj7My0HA03TUuJp5nUCAGA/ArRjh83+dDE7epJ7tD4YaByzwNOylHjaeZ0AANiP7wg7dtDsz8rS3Mizo32cYX1QrTXXN7bzmS+9lldubufcwkxKSidjnJalxNPO6wQAwH4EaMcOmv3pYm9cn/fX7cbx5/9sM5/84p+nJnn83HyevBcjo45xWpYSTzuvEwAA+zkz6QH01e5M3kvXN3N9Yzu11iP9vt3Znwftzv4cNDt6VF3c47iO+nexG8dbt+9k9zNevbmdm1t3Ohvj7lLip1aXsro8L2p6yusEAMBezIDuYZRlrgfN/jw4O1pTc3PrTrZ37uSr9VxqrUf6Jn2c++v22reZ5Mh/F7uBuTA7k5Lcj9CtnTs5vzBrDyAAAJxyZkD3sN8y1/XNnSP9/v1mf3ZnR2tqvrh+K5975WbOlJLPfvlGXnz5xpFmWQ+aYR3FbnR/7PPrD/3v+sb2kf8udgNz9kzy9OpSdvN0YW7GHkAAAMAM6F7G9RiJ3dnRxfmZ3Nq+kzc9tpjZM0lNOfIeyXHtr9svur+6TxTv9Xfx4OEzq8tzubD4WM6fnc1bL53PimWYAABw6gnQPYxzmWspJWdKydL83Xs9mHdHDdxxPFJlv+g+s0807vV34fAZAADgIAJ0D+N+jMQoe0HH8XzNR8f0oIvnF5LkyH8XrZ83yt7G9T4BAIBRCNA9jHMmr9aa1Jql+ZnceH0nX37t9Vy7sZ2nV5fy2S/fyK3tO/sedjTOZ4DuF927MWlWczj6/qxYAABOLwG6j3HM5D0YBjV3H21yppT85ScvZOZMOXQv6DifAXpYdO/+XZhZ678+PysWAIDTTYA29GAYlJSUUvLl117PxfNnU/O1iNtvL+hxD0c6biweFt1m1oZhXIdoAQDAqARoQ4+GwcLcTGqSrdt37h9KlBz/EKS9ro8jFk86s2bWtK3D3ideDwAAJkWANvRoGJxbmMnFc/NZmJ25f+2gA36OczjSOJZhnmRmzaxpewe9T7weAABMUicBWkp5d5KfTjKT5P211n/TxX2nzaNhUFLyjjev5okLZ7O5fefQ2ajjHI40jmWYJ3k8jf2I7R30Prm+se31AABgYkYO0FLKTJKfTfIdSa4m+aNSyn+ptX561HtPm4PC4I3HuMdRDkcax7NMT/J4GvsRJ2O/94nXAwCASepiBvQdST5ba/1ckpRSfinJ9yYRoHto9ZzMcTzL9CSPpxlHCHNyXg8AACapi+86n0zy0gMfX03yNzq4LyMY17NMjxvQ4whhTs7rAQDAJDWb9iilPJvk2SR5+umnW33Zpvp2umir2dbDxjCOEOZkvB4AAExSFwH6xSRPPfDx2r1rD6m1PpfkuSS5cuVK7eDr9sqkThftW/Tu5SjPF+37n2Ga9OEHEwAAnE5dBOgfJXlLKeXNuRue35fkH3Rw30GZxGmv0/BIjWn4MwAAAEdzZtQb1FpvJ/mRJL+d5IUkv1xr/dSo9x2ag04XHZf9ond9c2dsX7Nr6xvbeeHlG3n15lZubN1OTR3cnwEAADiaTvaA1lp/M8lvdnGvoWp9umitNa+89no2t29nYXYms2eSmrszhkN5pEatNZ95+Ub+zys37197/Nx8nlxZnPifwbJgAADonmcvdKTl6aK7y1ZfuBdvJcnTq0tZXZ5LTRnMIzXWN3dy4/XbKUl2NwW/enM7jy3NZ3lhdmIRaFkwAACMxzBKZQBani66u/T23MJMHj83n1dvbucL1zdzYfGxfOMbh/NIjY2t25k9czeev3B9MzVJSfLEufm8YXF2YhE4if28AABwGgjQDrU6XXR3X2lJyZMri3lsaT5bO3fy1OqwZumWF2ZTU7K6PJcLi49l6/adLMzO5K1vupCv3Lo9sQg8aD+vAAUAgJMb+RAi2ntwiW1JyfmF2Tx+biGXHlscTHwmX1u2XFMyc6ZkaX423/jGpawuz0/kUKddrffzAgDAaeE76gFqud90nA5atjzJCHzw77em5ubWnTxxbj611tRaBxX5AADQJwJ0gFruNx23/ZYtTzKy7//9nl/IZ16+ka9+NXl9504+/oWvOIwIAABGIEAHqtV+00mZdGSXUpJSsrl9JzNnyv1Teh1GBAAAJydA6a1JR7bDiAAAoFsOIYJ9OIwIAAC6JUAZu1prrm9s56Xrm7m+sZ1a6+G/qQd296E+aIiHPQEAQF+YymGsaq158eUbX3eY0BAO8pn0PtRH1VqzvrnTi7EAAMBJCNBTqGXIrG/uPBSfybAO8pn0PtRdQw55AADYJUBPmdYhM40H+UxiJnLoIQ8AAIkAPXVah0xfD/I5aUROaiZyGkOew1l2DQBMGwF6yrQOmd2DfB4Ntkke5DNKRE5qJrKvIc/4WHYNAEwj372eMq1Dpm8H+SSjReSkZiL7GPKMl2XXAMA0EqCnzCRCpi8H+ewaJSInNRPZx5BnvCy7BgCmkQA9ZVqHTB/3sI0SkZOciexbyDNell0DANPIdzKnUKuQ6esetlEi0kwkrVh2DQBMIwHK2PR1D9uoEWkmkhb8sAMAmEYClGM76rLaPu9hE5EMgfcpADBtBCjHcpxltfawAQAADzoz6QEwLPstq13f3Pm6z93dw/Yge9gAAOD0MhXFsRxnWa09bMPVx9OLAQAYPgHKsRx3Wa09bPvra+T19fRiAACGT4ByLB4N0Y0+R15fTy8GAGD4BCjHYlltN1pG3nFnWvt8ejEAAMMmQDm2Usr9Gc/dWBGhx9Mi8mqtub6xnc986bW8cnM75xZmUlIOnWl1ejEAAOPiO0qOrc/LR/u6r/JR44683dfo83+2mU9+8c9Tkzx+bj5P3ls+fdBMq2XWAACMiwDl2Pq6R7DPYfyocUfe7mu0dftO6r1rr97czmNL8zm/MHvgTOtpX2Y9lB9iAAAMkQDl2Pq6R7CvYbyXriJvv1jafY0WZmdSkvsRurVzJ+cXZg+daT2tpxcP6YcYAABDJEA5tr7uEexrGO9n1Mg7KJZ2X4vZM8nTq0v5wvXN1CQLczOW0x5gSD/EAAAYIgHKsfV1j2Bfw3hcDoqlB1+j1eW5XFh8LOfPzuatl85nZXnebN4+hvZDDACAoZnO78wZq77uEexrGI/LYbHUx9eo707bDzEAAFrzXRUn0sc9gn0N43E5LJb6+Br13Wn7IQYAQGsClKlymqJLLHXvtP0QAwCgNQEKAyWWxuM0/RADAKA1AQoDJpYAABiSM5MeAAAAAKeDAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoYnbSA4DjqrVmfXMnG1u3s7wwm5WluZRSJj0sAADgEAKUQam15sWXb+Tq+q3719ZWFnP50vlBRKh4BgDgNBOgjFXXwbW+ufNQfCbJ1fVbeeLC2awuz4863LEaejwDAMCoBChjM47g2ti6ve/1vgfokOMZAAC64BAixma/4Frf3DnxPZcX9v6ZyX7X++SgeAYAgNNAgDI24wiulaW5rK0sPnRtbWUxK0tzJ75nK/vG8/xMrm9s56Xrm7m+sZ1aa+ORHa7W2vsxAgDQf/2fNmKwxjFbWUrJ5Uvn88SFs4M7yGc3nh+cFX7yDWfzymuv5+pXXr9/rW/7Qu1dBQCgKwKUsdkruLqYrSylZHV5fnD7JveK51prPv6Frzz0eX3bF2rvKgAAXRGgjM2QZyvH5dF4fun65p6f16dDlYZ88BMAAP0iQBmroc5WtjKEQ5WGMEYAAIbBIUQwQUM4VGkIYwQAYBhMYcAEDWGZ8hDGCADAMAhQmLAhLFMewhgBAOg/S3ABAABoQoACAADQhCW4wMhqrVnf3LFHFACAAwlQYCS11rz48o1cXb91/9raymIuXzovQgEAeIgluMBI1jd3HorPJLm6fivrmzsTGhEAAH0lQIGRbGzdPtb1Wmuub2znpeubub6xnVrrOIcHAECPWIILjGR5Ye//G9nruuW6AACn20gzoKWUv19K+VQp5aullCtdDQoYjpWluaytLD50bW1lMStLc1/3uZbrAgCcbqPOgH4yyd9L8h86GAswQKWUXL50Pk9cOHvoKbgHLdddXZ4f91ABAJiwkQK01vpCEkvn4JQrpWR1ef7QiDzOcl0AAKaPQ4iAZo6zXBcAgOlz6LRDKeV3k1za45feV2v99aN+oVLKs0meTZKnn376yAMEpsdxlusCADB9Dg3QWuu3d/GFaq3PJXkuSa5cueK5C3BKHXW5bldqrVnf3BG8AAA9YOMVMLU89gUAoF9GfQzL3y2lXE3yrUn+aynlt7sZFsDoPPYFAKBfRj0F94NJPtjRWAA65bEvAAD94hRcYGp57AsAQL8IUGBqjeOxL7XWXN/YzkvXN3N9Yzu1OlMNAOCoTAMAU6vrx7441AgAYDQCFJhqXT72Zb9DjZ64cNaeUgCAI7AEF+CIDjrUCACAwwlQgCNyqBEAwGgEKMARjeNQIwCA08SP7QGOqOtDjQAAThsBCnAMXR5qBABw2liCCwAAQBMCFAAAgCYEKAAAAE3YAwrAVKq1Zn1zx4FRANAjAhSAqVNrzYsv38jV9Vv3r62tLObypfMiFAAmyBJcAKbO+ubOQ/GZJFfXb2V9c2dCIwIAEgEKwBTa2Lp9rOsAQBsCFICps7yw9w6T/a4DAG0IUACmzsrSXNZWFh+6traymJWluQmNCABIHEIEwBQqpeTypfN54sJZp+ACQI8IUACmUiklq8vzWV2en/RQAIB7BCgMmOccAgAwJAIUBspzDgEAGBqHEMFAec4hAABDI0BhoDznEACAoRGgMFCecwgAwNAIUBgozzkEAGBoTJXAQHnOIQAAQyNAYcA85xAAgCERoADAvjxvGIAuCVAAYE+eNwxA1xxCBMCpV2vN9Y3tvHR9M9c3tlNrnfSQesHzhgHomhlQAE41s3z7O+h5w/aeA3ASZkABONXM8u3P84YB6JoABeBUO2iW77TzvGEAuuZHmACcamb59ud5wwB0zX9dATjVdmf5Ht0DapbvLs8bBqBLAhSAU80sHwC0I0ABOPXM8gFAGw4hAgAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaEKAAAAA0IUABAABoQoACAADQhAAFAACgCQEKAABAEwIUAACAJgQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCZmJz0AgCGqtWZ9cycbW7ezvDCblaW5lFImPSwAgF4ToADHVGvNiy/fyNX1W/evra0s5vKl8yIUAOAAIy3BLaX8RCnlM6WUPy6lfLCU8oaOxgXQW+ubOw/FZ5JcXb+V9c2dCY0IAGAYRt0D+qEkb6u1fnOSP0ny3tGHBNBvG1u3j3UdAIC7RgrQWuvv1Fp3v+P6cJK10YcE0G/LC3vvXtjvOgAAd3V5Cu4PJ/mtDu8H0EsrS3NZW1l86NraymJWluYmNCIAgGE49Mf1pZTfTXJpj196X6311+99zvuS3E7ygQPu82ySZ5Pk6aefPtFgAfqglJLLl87niQtnnYILAHAMpdY62g1K+aEk/zjJu2qtm0f5PVeuXKnPP//8SF8XAACAfiqlfLTWeuXR6yNtWCqlvDvJjyf520eNTwAAAE6nUfeA/kyS80k+VEr5RCnl33cwJgAAAKbQSDOgtda/2NVAAAAAmG5dnoILAAAA+xKgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBMCFAAAgCYEKAAAAE0IUAAAAJoQoAAAADQhQAEAAGhCgAIAANCEAAUAAKAJAQoAAEATAhQAAIAmBCgAAABNCFAAAACaKLXW9l+0lGtJPn+ET308yatjHg6ni/cU4+B9Rde8p+ia9xTj4H3FQb6x1nrx0YsTCdCjKqU8X2u9MulxMD28pxgH7yu65j1F17ynGAfvK07CElwAAACaEKAAAAA00fcAfW7SA2DqeE8xDt5XdM17iq55TzEO3lccW6/3gAIAADA9+j4DCgAAwJTofYCWUn6ilPKZUsofl1I+WEp5w6THxDCVUt5dSnmxlPLZUsq/nPR4GLZSylOllN8vpXy6lPKpUsp7Jj0mpkMpZaaU8vFSym9MeixMh1LKG0opv3Lv+6kXSinfOukxMWyllH9x7799nyyl/GIp5eykx8Rw9D5Ak3woydtqrd+c5E+SvHfC42GASikzSX42yd9J8k1Jvr+U8k2THRUDdzvJj9VavynJtyT5p95TdOQ9SV6Y9CCYKj+d5L/VWt+a5K/E+4sRlFKeTPLPk1yptb4tyUyS75vsqBiS3gdorfV3aq2373344SRrkxwPg/WOJJ+ttX6u1rqd5JeSfO+Ex8SA1Vq/VGv92L1/v5G739A9OdlRMXSllLUk35Xk/ZMeC9OhlPJYkr+V5OeSpNa6XWv9ykQHxTSYTbJYSplNspTkTyc8Hgak9wH6iB9O8luTHgSD9GSSlx74+GrEAh0ppTyT5O1JPjLhoTB8P5Xkx5N8dcLjYHq8Ocm1JP/x3tLu95dSlic9KIar1vrFJP82yReSfCnJn9daf2eyo2JIehGgpZTfvbeG/NF/vveBz3lf7i55+8DkRgrwsFLKuSS/muRHa62vTXo8DFcp5buTvFJr/eikx8JUmU3y15L8u1rr25NsJHEOAidWSlnJ3VVkb07yF5Isl1J+YLKjYkhmJz2AJKm1fvtBv15K+aEk353kXdVzYziZLyZ56oGP1+5dgxMrpczlbnx+oNb6a5MeD4P3ziTfU0r5ziRnk1wopfxCrdU3doziapKrtdbdFRq/EgHKaL49yf+ttV5LklLKryX5m0l+YaKjYjB6MQN6kFLKu3N3OdL31Fo3Jz0eBuuPkryllPLmUsp87m6W/y8THhMDVkopubun6oVa609OejwMX631vbXWtVrrM7n7/1G/Jz4ZVa315SQvlVIu37v0riSfnuCQGL4vJPmWUsrSvf8WvisOtuIYejEDeoifSbKQ5EN33+P5cK31n0x2SAxNrfV2KeVHkvx27p7W9vO11k9NeFgM2zuT/GCS/11K+cS9a/+q1vqbkxsSwJ7+WZIP3PsB7OeS/MMJj4cBq7V+pJTyK0k+lrvb4z6e5LnJjoohKVa0AgAA0ELvl+ACAAAwHQQoAAAATQhQAAAAmhCgAAAANCFAAQAAaEKAAgAA0IQABQAAoAkBCgAAQBP/H3Lvf58r3VFmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=X1[:,0], y=X1[:,1],\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 16)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'plotly' has no attribute 'scatter_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-8937eb1070ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fig = px.scatter_matrix(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagonal_visible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/_plotly_utils/importers.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(import_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \"module {__name__!r} has no attribute {name!r}\".format(\n\u001b[1;32m     41\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'plotly' has no attribute 'scatter_matrix'"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    X1,\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_drop = clean_dtf[clean_dtf[\"ID\"].isin(id_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dtf_drop[\"Score\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b64bd418fb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_reclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtf_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marticle_cleaner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8740\u001b[0m         )\n\u001b[0;32m-> 8741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b64bd418fb20>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(line)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_reclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtf_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marticle_cleaner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repo/github/RAPMC/scripts/article_cleaner.py\u001b[0m in \u001b[0;36mextract_match\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# Try first match with inital variation value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# Quality score = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0minitial_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_match\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m#print(\"First match ! \", variation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/github/RAPMC/scripts/article_cleaner.py\u001b[0m in \u001b[0;36mfind_match\u001b[0;34m(text, word)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mbefore_after_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"([^.]*\\.){0,1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mmatch_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmatch_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mfinal_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_tuple_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_reclean = dtf_drop.head(2).apply(lambda line: article_cleaner.extract_match(line), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('results:we identified 3 279 aml/mds patients expressingcbl exon 8/9 deletion mutants three four cases diagnosis expressed deleted transcripts missing exon 8 exon 8/9 aml/mds patients identified cbl mutants belonged core bindingfactor 11q deletion aml subtypes functionally cbl negatively regulated fmslike tyrosine kinase 3 flt3 activity interacted human flt3 via autophosphorylation sitesy589 andy599 colocalized vivo cbl-70z carrying internal deletion 17 amino acids isolated 70z/ 3 mouse pre-b-cell lymphoma cell line 4 cbl-70z deregulates cellular tyrosine kinase machinery nih3t3 serumstarved cells expressing cbl-70z showed significantly increased endothelial growth factor receptor egfr kinase activity egf stimulation 5 additional screenings aml patients revealed cases cbl mutations including internal deletions exon 8 point mutations targeting g375 10 11 activating flt3 mutations represent one common genetic alterations aml associated poor prognosis 12 finally cbl deletion mutants cbldexon8 cbl exon8/9 transformed ba/f3 cells presence absence flt3-wt materials methods analysis cell lines patient samples analysis large cohort aml/mds patients different cytogenetic subgroups revealed overall low frequency cbl exon 8+9 deletions % however identified preferential association cbl exon8/9 mutations core bindingfactor leukemias 11q aberrations describe known human cbl deletion mutants lead transformation wild-type flt3 ^ expressing hematopoietic cells phenotype resembles seen activated receptor tyrosine kinases obtain comprehensive insight role cbl human acute leukemias firstly pcr screening cdna 61aml 21acute lymphoblastic leukemia all cell lines table 1; supplementary table s1 deletions linker ring finger domains identified monoallelic cbl deletion transcript aml cell line molm-13 sister cell line molm-14 patient 1 t8;21 aml1/eto positive patient 2 11q deletion expressed cbl transcript lacking exon 8 patient 3 inv16 cbfb/myh11 positive expressed cbl lacking exon 8 9 table 1b; 1a pcr fragment analysis determined relative expression mutant versus cbl-wt murine cbl deletion transcript described 70z/3 b-cell lymphoma cell line cbl-70z lacking first 17 amino acids exon 8; ref 4 analysis genomic dna molm-13 cells detected deletion 14 nucleotides exon 8/intron 8 boundary eliminating table 1 a one allele patient 1cbldexon8 harbored deletion 43 nucleotides exon 8-intron 8 boundary including last 36 nucleotides exon 8 first 7 nucleotides intron 8 thereby losing whole splice donor site intron 8 analysis genomic dna patient 2 cbldexon8 revealed point mutation splice donor site intron 8 changing conserved ‘‘gt’’ ‘‘gc’’ 10% amplified dna patient 3 cbldexon8+9 carries monoallelic large genomic deletion 1680 nucleotides starting intron 7 ending intron 9 leading loss exon 8 9 conclusion cbl transcripts lack whole exons explained genomic events target splice donor acceptor sites mutations deletions shown cbl deletion mutants cbldexon8 cbldexon8+9 found aml patients cbl-70z known oncogenic form cbl comprisinga deletion first 17 amino acids within exon 8 location r420 found mutated one aml patient study red squares mutated region within cbl protein patient samples diagnosis two remission controls patient 1and patient 3 analyzed deletions molm-13 cells served positive control compared cbl deletion mutants expression cbl r420g r420q g375s g375p point mutants confer proliferative capacity enhanced cell survival 50% cells survived 3 days il-3 withdrawal compared 10% survival control cells data shown presence flt3 ligand induced strong dosedependent proliferation flt3-wt/cbl-70z flt3-wt/ cbldexon8 flt3-wt/cbldexon8+9 cotransduced cells 2 coexpression cbl deletion mutants flt3-wt autoactivates flt3 receptor known classes flt3 mutations shown autoactivate kinase activity flt3 16 27– 30 prepared lysates flt3 ligand – stimulated nonstimulated ba/f3 cells coexpressing flt3- wt cbl deletion mutant immunoprecipitated flt3 receptor analyzed tyrosine phosphorylation contrast flt3-wt- flt3-wt/cbl-wt –expressing cells three cbl mutant–expressing cells displayed autophosphorylated flt3 absence flt3 ligand  4a cbl deletion mutants induce transformingpotential flt3-wt ^ expressingba/f3 cells respond flt3 ptk inhibitor treatment a cells stably transduced flt3-wtalone flt3-wtand cbl-wt cbl-70z cbldexon8 cbldexon8+9 cultured absence il3 72 h viable cells counted trypan blue exclusion b cells analyzed accordingto a different concentrations fl 100 ng/ml added culture medium confirms hypothesis coexpression cbl deletion mutant cbl-wt leads remarkable stabilization flt3 protein within cells inhibiting down-regulation degradation flt3 protein analysis phosphorylation status transduced cbl flt3-wt/cbl mutant –expressing cells revealed cbl mutants became phosphorylated stimulation cells flt3 ligand  4b coexpression cbl deletion mutants autoactivates flt3 cbl mutants downstream signaling pathways stat5 akta mock flt3-wt flt3-wt/cbl-wt flt3-wt/cbl-70z flt3-wt/cbldexon8 flt3-wt/ cbldexon8+9 cells starved 24 h presence % fcs unstimulated stimulated 100 ng/ml flt3 ligand 5 min flt3 immunoprecipitated polyclonal flt3 antibody analyzed immunoblottingwith phospho-tyrosine antibody stripped reprobed flt3 antibody indeed three patients carried genomic lesions affecting splice donor acceptor sites mutation deletion clearly exclude aberrant splicing events within malignant clone note detected preferential association cbl mutations specific subtypes aml/mds two 13 patients 11q deletions found positive [% % %] aml/mds subgroup shows highest flt3 expression among aml subgroups 41 cbl mutations might event causing high flt3 expression aberrant flt3 activation patients cells coexpressing flt3-wt cbl deletion mutant able proliferate absence il-3 cbl point mutants coexpressed flt3wt showed enhanced survival proliferative capacity baf3 cells addition exogenous flt3 ligand induced rapid proliferative response flt3-wt cbl deletion mutant – coexpressing cells aml blasts coexpress flt3 ligand leading autocrine stimulation phenotype mimics vivo situation 47 48 analyzing internalization rate flt3 flt3-wt flt3-wt/cbl-70z cells revealed difference rate speed internalization; thus early steps endocytosis flt3 seem affected presence cbl deletion mutant concert study jiang  late stages endocytosis recruitment egfr coated pits affected cbl-70z 48 cbl deletion mutants show transforming phenotype baf3 cells presence flt3 resembles phenotype seen flt3-activating mutations flt3-itd flt3-tkd flt3-jm-pm new mechanism activation mutated negative-regulatory molecules rtks opens door treating patients ptk inhibitors carry mutations rtk itself sequenced c-cbl cbl-b cbl-c patients without corresponding upd deletions correlated mutational status clinical features outcomes results identified c-cbl mutations 5% 9% patients chronic myelomonocytic leukemia cmml saml also cml blast crisis juvenile myelomonocytic leukemia jmml loh arise either via hemizygous deletion dna segment lost one homolog remains one copy per cell uniparental disomy upd wherein retained homolog duplicated preserve two total copies per cell locus thus analysis recurrent regions loh may point toward presence important mutations5–7 recently metaphase cytogenetics applied detection chromosomal defects including deletions resulting loh using technique number invariant chromosomal abnormalities described minimal affected regions delineated pointing towards potentially pathogenic genes loh also result deletions deletions involving 11q found 29 patients fig 1c sequencing c-cbl revealed mutations 13 cases 76% upd11q however among patients deletion11q c-cbl mutation found one case cmml also analyzed patients without loh11q assess frequency heterozygous mutations identified five cases % also found hemizygous mutation linker sequence cmml patient microdeletion 11q previously undetected metaphase cytogenetics appendix fig a2 online only eleven mutations found cmml similar forms mds/mpn unclassifiable either time testing; 6 patients progressed saml 55%jpg microdeletion 11q detected c-cbl patient chronic myelomonocytic leukemia 1 leading hemizygous insertion mutation linker sequence bm bone marrowjpg patient saml evolved myelodysplastic/myeloproliferative neoplasms chromosome 3 abnormality seen metaphase cytogenetics single nucleotide polymorphism array analysis revealed deletion region cbl-b direct sequencing whole bone marrow bm showed hemizygous mutation 1204-51 g>a intron 9 whereas mutation detected cd3+ lymphocytes cbl exon 8 deletions mutations described cbl large deletions involving exon 8 ring finger domain1821–232930323742 design mutation screening assay able detect them we therefore designed new pcr assay primers located exon 7 intron 9 e7fw: 5’-tcctgatggac-gaaatcaga-3’; e9-rv: 5’-ctcacaatggattttgccagt-3’ would amplify normal fragment 989 b assay large deletion exon 8 would detected product smaller size71955_71955a deletion exon 8 frameshift change truncates ring finger domain loss proline-rich uba carboxy-terminal domains t402hfsx29 figure 1 cbl exon 8 deletions observed case also detected previously reported substitution g',\n",
       "  7)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text_reclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (366, 1), indices imply (366, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1f6521305920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtf_reclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_reclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    709\u001b[0m                     )\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    712\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (366, 1), indices imply (366, 2)"
     ]
    }
   ],
   "source": [
    "dtf_reclean = pd.DataFrame(list(text_reclean), columns = [\"Text\",\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_reclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_length > 512).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = clean_text.apply(lambda x: get_chunks(x.split(), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14592"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features(chunked_text[9], tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = short.apply(lambda line: tokenizer.encode(line, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2182,\n",
       " 2139,\n",
       " 2953,\n",
       " 21890,\n",
       " 3490,\n",
       " 4371,\n",
       " 3729,\n",
       " 2243,\n",
       " 10790,\n",
       " 12151,\n",
       " 22330,\n",
       " 20464,\n",
       " 2378,\n",
       " 1049,\n",
       " 4031,\n",
       " 6904,\n",
       " 2213,\n",
       " 27814,\n",
       " 2050,\n",
       " 8031,\n",
       " 4256,\n",
       " 14494,\n",
       " 4962,\n",
       " 16014,\n",
       " 6438,\n",
       " 19817,\n",
       " 4609,\n",
       " 10719,\n",
       " 22330,\n",
       " 20464,\n",
       " 2378,\n",
       " 3378,\n",
       " 2732,\n",
       " 8715,\n",
       " 3005,\n",
       " 2838,\n",
       " 2421,\n",
       " 11756,\n",
       " 19962,\n",
       " 2850,\n",
       " 6593,\n",
       " 8516,\n",
       " 2100,\n",
       " 10093,\n",
       " 19281,\n",
       " 3372,\n",
       " 9825,\n",
       " 2019,\n",
       " 23924,\n",
       " 18400,\n",
       " 25125,\n",
       " 15451,\n",
       " 14192,\n",
       " 10708,\n",
       " 21770,\n",
       " 10624,\n",
       " 9096,\n",
       " 3995,\n",
       " 2271,\n",
       " 3801,\n",
       " 2184,\n",
       " 2174,\n",
       " 4972,\n",
       " 22330,\n",
       " 20464,\n",
       " 2378,\n",
       " 26835,\n",
       " 19009,\n",
       " 2732,\n",
       " 8715,\n",
       " 3961,\n",
       " 4242,\n",
       " 8290,\n",
       " 6887,\n",
       " 16515,\n",
       " 13874,\n",
       " 2036,\n",
       " 5159,\n",
       " 2440,\n",
       " 1011,\n",
       " 3091,\n",
       " 22330,\n",
       " 20464,\n",
       " 2378,\n",
       " 3729,\n",
       " 2243,\n",
       " 10790,\n",
       " 8171,\n",
       " 5228,\n",
       " 17395,\n",
       " 8336,\n",
       " 4414,\n",
       " 1055,\n",
       " 2487,\n",
       " 2050,\n",
       " 7718,\n",
       " 2367,\n",
       " 11163,\n",
       " 22694,\n",
       " 3729,\n",
       " 2243,\n",
       " 10790,\n",
       " 22330,\n",
       " 20464,\n",
       " 2378,\n",
       " 14802,\n",
       " 4522,\n",
       " 4962,\n",
       " 11867,\n",
       " 2140,\n",
       " 102]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(clean_dtf['Class'].head(100)).values\n",
    "Y = clean_dtf['Class'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     2\n",
       "2     2\n",
       "3     3\n",
       "4     4\n",
       "     ..\n",
       "95    4\n",
       "96    4\n",
       "97    2\n",
       "98    4\n",
       "99    4\n",
       "Name: Class, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5035406 , -0.00647518, -0.21705078, ..., -0.5287751 ,\n",
       "         0.2916012 ,  0.08589556],\n",
       "       [-0.5125765 , -0.13349567, -0.28608534, ..., -0.38054252,\n",
       "         0.4418598 ,  0.18841559],\n",
       "       [-0.5125765 , -0.13349567, -0.28608534, ..., -0.38054252,\n",
       "         0.4418598 ,  0.18841559],\n",
       "       ...,\n",
       "       [-0.38632408, -0.11147138, -0.24998908, ..., -0.26752406,\n",
       "         0.3377955 ,  0.20002049],\n",
       "       [-0.49237314, -0.10175788, -0.19333296, ..., -0.36747196,\n",
       "         0.21361321,  0.21201032],\n",
       "       [-0.62655467, -0.16094612, -0.09694041, ..., -0.37923616,\n",
       "         0.41551352,  0.29649997]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "XD_train, XD_test, YD_train, YD_test = train_test_split(x_input, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1536, 1) (80, 7)\n",
      "(20, 1536) (20, 7)\n"
     ]
    }
   ],
   "source": [
    "print(XD_train.shape, YD_train.shape)\n",
    "print(XD_test.shape, YD_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3.8374178 ],\n",
       "        [ -0.8922846 ],\n",
       "        [  2.678097  ],\n",
       "        ...,\n",
       "        [  8.772786  ],\n",
       "        [-11.581604  ],\n",
       "        [-19.514511  ]],\n",
       "\n",
       "       [[ 16.59914   ],\n",
       "        [ 11.089554  ],\n",
       "        [  4.3075833 ],\n",
       "        ...,\n",
       "        [  0.5510696 ],\n",
       "        [ -6.1170044 ],\n",
       "        [ -2.75785   ]],\n",
       "\n",
       "       [[  0.9374429 ],\n",
       "        [  3.643863  ],\n",
       "        [ -2.0823832 ],\n",
       "        ...,\n",
       "        [-12.1003895 ],\n",
       "        [  9.657788  ],\n",
       "        [ 18.876177  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-18.095444  ],\n",
       "        [-12.209627  ],\n",
       "        [ -1.3705101 ],\n",
       "        ...,\n",
       "        [  0.3859473 ],\n",
       "        [  0.10363049],\n",
       "        [ -4.2583976 ]],\n",
       "\n",
       "       [[ 11.547639  ],\n",
       "        [  4.88629   ],\n",
       "        [  7.66245   ],\n",
       "        ...,\n",
       "        [ -7.903171  ],\n",
       "        [  7.5490017 ],\n",
       "        [ 12.783539  ]],\n",
       "\n",
       "       [[ 12.301475  ],\n",
       "        [  6.1728168 ],\n",
       "        [ -0.267828  ],\n",
       "        ...,\n",
       "        [ -7.542435  ],\n",
       "        [  6.459732  ],\n",
       "        [ 10.399831  ]]], dtype=float32)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XD_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "XD_train = XD_train.values.reshape(80,1536,1)\n",
    "# YD_train = YD_train.reshape(80,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 1534, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 767, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 765, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 382, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24448)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 171143    \n",
      "=================================================================\n",
      "Total params: 177,479\n",
      "Trainable params: 177,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv1D(32, kernel_size = [3], activation = \"relu\", input_shape = (XD_train.shape[1],1)),\n",
    "    layers.MaxPooling1D(pool_size = [2]),\n",
    "    layers.Conv1D(64, kernel_size = [3], activation = \"relu\"),\n",
    "    layers.MaxPooling1D(pool_size = [2]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(units = 7,  activation = \"softmax\")      \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = \"adam\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 244ms/step - loss: 3.4228 - accuracy: 0.3281 - val_loss: 18.5837 - val_accuracy: 0.1875\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.18750, saving model to ../../results/model_BERT.h5\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 12.3842 - accuracy: 0.1562 - val_loss: 15.2993 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.18750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 4.9695 - accuracy: 0.4688 - val_loss: 16.6440 - val_accuracy: 0.3125\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.18750 to 0.31250, saving model to ../../results/model_BERT.h5\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5.3238 - accuracy: 0.5312 - val_loss: 13.7241 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.31250\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.8325 - accuracy: 0.5000 - val_loss: 10.3076 - val_accuracy: 0.1875\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.31250\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('../../results/model_BERT.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "\n",
    "train_sh = model.fit(\n",
    "    XD_train, YD_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint,earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including bert in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import size\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.python.keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from transformers.utils.dummy_pt_objects import NoBadWordsLogitsProcessor\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import transformers as ppb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from transformers import AutoTokenizer,TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(data):\n",
    "    sw = stopwords.words(\"english\")\n",
    "    # lowercase text\n",
    "    # data = data.apply(lambda x: \" \".join(i.lower() for i in  str(x).split()))\n",
    "#     # remove numeric values\n",
    "#     data = data.str.replace(\"\\d\",\"\")\n",
    "#     # remove punctuations\n",
    "#     data = data.str.replace(\"[^\\w\\s]\",\"\")\n",
    "    # remove stopwords: the,a,an etc.\n",
    "    data = data.apply(lambda x: \" \".join(i for i in x.split() if i not in sw))\n",
    "    data = data.apply(lambda x: re.sub(\"⇓\",\"\",x))\n",
    "    data = data.apply(lambda x: re.sub(\",|\\)|\\(|\\.\",\"\",x))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def get_data(data_file):\n",
    "    \n",
    "    dtf = pd.read_csv(data_file, sep = \"\\|\\|\", engine = \"python\")\n",
    "    X = pre_processing(dtf[\"Text\"])\n",
    "    dataset = dtf.drop(columns = [\"Score\"], axis = 0)\n",
    "    return X, dataset\n",
    "\n",
    "\n",
    "def lemm(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    temp = []\n",
    "    list_words = list(set(word_tokenize(text)))\n",
    "    for word in list_words:\n",
    "        if len(word) > 2:\n",
    "            temp.append(lemmatizer.lemmatize(word))\n",
    "    return list(set(temp))\n",
    "\n",
    "\n",
    "\n",
    "def get_chunks(text_split):\n",
    "    length_text = len(text_split)\n",
    "    size = int(len(text_split) / 20)\n",
    "    final = []\n",
    "    for i in range(0, length_text, size):\n",
    "        final += [\" \".join(text_split[i:i+size])]\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "def get_features(article, tokenizer, model):\n",
    "    nb_chunk = 20\n",
    "    chunked_article = get_chunks(article)\n",
    "\n",
    "    features = []\n",
    "    for c in range(nb_chunk):\n",
    "        token = []\n",
    "        max_len = 0\n",
    "        token.append(tokenizer.encode(chunked_article[c], add_special_tokens=True))\n",
    "        for i in token:\n",
    "            if len(i) > max_len:\n",
    "                max_len = len(i)\n",
    "\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len-len(i)) for i in token])\n",
    "\n",
    "        if len(padded[0]) > 500:\n",
    "            padded = np.array([padded[0][:500]])\n",
    "            if padded[0][-1] != 103:\n",
    "                padded = np.append(padded[0],(103))\n",
    "        \n",
    "        input_ids = torch.tensor(padded)  \n",
    "        \n",
    "        attention_mask = np.where(padded != 0, 1, 0)                       \n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "        try:\n",
    "            attention_mask.shape[1]\n",
    "        except:\n",
    "            attention_mask = attention_mask.reshape(1, attention_mask.shape[0])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "        return input_ids, attention_mask\n",
    "    \n",
    "    \n",
    "#         features.append(last_hidden_states[0][:,0,:].numpy()[0])\n",
    "#     array = np.array(features)\n",
    "#     print(\"SHAPE\", array.shape)\n",
    "#     return array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer_scibert = ppb.AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model_scibert = ppb.AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dtf = pd.read_csv(\"../datas/all_data_clean_011.txt\", sep = \"\\|\\|\", engine = \"python\")\n",
    "\n",
    "clean_text = pre_processing(clean_dtf[\"Text\"])\n",
    "split_text = clean_text.apply(lambda line: line.split())\n",
    "clean_dtf[\"Text\"] = split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>truncating mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>[mutations, gene, predict, absence, truncation...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>w802*</td>\n",
       "      <td>2</td>\n",
       "      <td>[using, select, c-cbl, somatic, mutations, s80...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>q249e</td>\n",
       "      <td>2</td>\n",
       "      <td>[using, select, c-cbl, somatic, mutations, s80...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>n454d</td>\n",
       "      <td>3</td>\n",
       "      <td>[15, apart, n454d, residues, affected, missens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>l399v</td>\n",
       "      <td>4</td>\n",
       "      <td>[finally, third, group, constituted, mutations...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3316</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>d171n</td>\n",
       "      <td>4</td>\n",
       "      <td>[confirm, involvement, aml1, mutations, hemato...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3317</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>a122*</td>\n",
       "      <td>1</td>\n",
       "      <td>[histopathologic, findings, b, spleen, d, live...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3318</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>fusions</td>\n",
       "      <td>1</td>\n",
       "      <td>[out-of-frame, fusions, rhd, runx1, retained, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3319</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>r80c</td>\n",
       "      <td>4</td>\n",
       "      <td>[runx1, mutants, r80c, k83n, k83e, showed, str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3320</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>k83e</td>\n",
       "      <td>4</td>\n",
       "      <td>[electropherograms, affected, control, individ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    Gene             Variation  Class  \\\n",
       "0        0  FAM58A  truncating mutations      1   \n",
       "1        1     CBL                 w802*      2   \n",
       "2        2     CBL                 q249e      2   \n",
       "3        3     CBL                 n454d      3   \n",
       "4        4     CBL                 l399v      4   \n",
       "...    ...     ...                   ...    ...   \n",
       "3311  3316   RUNX1                 d171n      4   \n",
       "3312  3317   RUNX1                 a122*      1   \n",
       "3313  3318   RUNX1               fusions      1   \n",
       "3314  3319   RUNX1                  r80c      4   \n",
       "3315  3320   RUNX1                  k83e      4   \n",
       "\n",
       "                                                   Text  Score  \n",
       "0     [mutations, gene, predict, absence, truncation...      2  \n",
       "1     [using, select, c-cbl, somatic, mutations, s80...      1  \n",
       "2     [using, select, c-cbl, somatic, mutations, s80...      1  \n",
       "3     [15, apart, n454d, residues, affected, missens...      1  \n",
       "4     [finally, third, group, constituted, mutations...      1  \n",
       "...                                                 ...    ...  \n",
       "3311  [confirm, involvement, aml1, mutations, hemato...      1  \n",
       "3312  [histopathologic, findings, b, spleen, d, live...      2  \n",
       "3313  [out-of-frame, fusions, rhd, runx1, retained, ...      1  \n",
       "3314  [runx1, mutants, r80c, k83n, k83e, showed, str...      1  \n",
       "3315  [electropherograms, affected, control, individ...      1  \n",
       "\n",
       "[3316 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9dd9c7f105c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_masks_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'masked_token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_scibert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
    "X = model_scibert(input_ids, attention_mask=input_masks_ids)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'input_token')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
